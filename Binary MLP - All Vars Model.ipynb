{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceefd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a728f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data and generate Dummy Variables for Movement\n",
    "dta = pd.read_excel('Full Data - Unseparated.xlsx')\n",
    "classification_dta=pd.get_dummies(dta, columns=['Movement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ad0011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Net</th>\n",
       "      <th>SC-RPD</th>\n",
       "      <th>SC-Logit</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>N225</th>\n",
       "      <th>HSI</th>\n",
       "      <th>SSE</th>\n",
       "      <th>ER</th>\n",
       "      <th>JKSE</th>\n",
       "      <th>dJKSE</th>\n",
       "      <th>Movement_0</th>\n",
       "      <th>Movement_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1074</td>\n",
       "      <td>1035</td>\n",
       "      <td>1194</td>\n",
       "      <td>-0.018492</td>\n",
       "      <td>-0.016056</td>\n",
       "      <td>23719.370</td>\n",
       "      <td>19345.769531</td>\n",
       "      <td>24300.330078</td>\n",
       "      <td>2825.904053</td>\n",
       "      <td>15820.00</td>\n",
       "      <td>4649.079102</td>\n",
       "      <td>-12.592529</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>15303</td>\n",
       "      <td>6199</td>\n",
       "      <td>24283</td>\n",
       "      <td>-0.423402</td>\n",
       "      <td>-0.392434</td>\n",
       "      <td>23555.070</td>\n",
       "      <td>19498.500000</td>\n",
       "      <td>24367.865235</td>\n",
       "      <td>2796.631104</td>\n",
       "      <td>15725.00</td>\n",
       "      <td>4636.486572</td>\n",
       "      <td>-6.296265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>16804</td>\n",
       "      <td>5511</td>\n",
       "      <td>16002</td>\n",
       "      <td>-0.506072</td>\n",
       "      <td>-0.484156</td>\n",
       "      <td>23472.920</td>\n",
       "      <td>19270.950196</td>\n",
       "      <td>24401.632813</td>\n",
       "      <td>2811.957032</td>\n",
       "      <td>15677.50</td>\n",
       "      <td>4630.190308</td>\n",
       "      <td>-3.148132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>16430</td>\n",
       "      <td>6543</td>\n",
       "      <td>13197</td>\n",
       "      <td>-0.430375</td>\n",
       "      <td>-0.399841</td>\n",
       "      <td>23431.845</td>\n",
       "      <td>19157.175293</td>\n",
       "      <td>24418.516602</td>\n",
       "      <td>2819.619995</td>\n",
       "      <td>15653.75</td>\n",
       "      <td>4627.042175</td>\n",
       "      <td>-3.148132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>19198</td>\n",
       "      <td>7668</td>\n",
       "      <td>16663</td>\n",
       "      <td>-0.429167</td>\n",
       "      <td>-0.398557</td>\n",
       "      <td>23390.770</td>\n",
       "      <td>19043.400391</td>\n",
       "      <td>24426.958496</td>\n",
       "      <td>2783.048096</td>\n",
       "      <td>15630.00</td>\n",
       "      <td>4623.894043</td>\n",
       "      <td>82.597168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Neg   Pos    Net    SC-RPD  SC-Logit       DJIA          N225  \\\n",
       "0 2020-04-09   1074  1035   1194 -0.018492 -0.016056  23719.370  19345.769531   \n",
       "1 2020-04-10  15303  6199  24283 -0.423402 -0.392434  23555.070  19498.500000   \n",
       "2 2020-04-11  16804  5511  16002 -0.506072 -0.484156  23472.920  19270.950196   \n",
       "3 2020-04-12  16430  6543  13197 -0.430375 -0.399841  23431.845  19157.175293   \n",
       "4 2020-04-13  19198  7668  16663 -0.429167 -0.398557  23390.770  19043.400391   \n",
       "\n",
       "            HSI          SSE        ER         JKSE      dJKSE  Movement_0  \\\n",
       "0  24300.330078  2825.904053  15820.00  4649.079102 -12.592529           1   \n",
       "1  24367.865235  2796.631104  15725.00  4636.486572  -6.296265           1   \n",
       "2  24401.632813  2811.957032  15677.50  4630.190308  -3.148132           1   \n",
       "3  24418.516602  2819.619995  15653.75  4627.042175  -3.148132           1   \n",
       "4  24426.958496  2783.048096  15630.00  4623.894043  82.597168           0   \n",
       "\n",
       "   Movement_1  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_dta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4cd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Input and Output for the Model\n",
    "x=classification_dta.drop(columns=['Date', 'Neg', 'Pos', 'Net', 'SC-Logit', 'JKSE', 'dJKSE', 'Movement_0', 'Movement_1'])\n",
    "y=classification_dta[['Movement_0', 'Movement_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7fb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Train and Test Batches\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Data Standardization\n",
    "scaler=StandardScaler()\n",
    "x_train=pd.DataFrame(scaler.fit_transform(x_train))\n",
    "x_test=pd.DataFrame(scaler.fit_transform(x_test))\n",
    "\n",
    "#Neural Network Model Initiation\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(4, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam(learning_rate=0.0008),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('binary_model{epoch:08d}.h5', save_freq=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86da422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.7470 - accuracy: 0.5822 - val_loss: 0.7334 - val_accuracy: 0.5926\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7436 - accuracy: 0.5869 - val_loss: 0.7298 - val_accuracy: 0.5926\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7407 - accuracy: 0.5915 - val_loss: 0.7264 - val_accuracy: 0.5741\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.5869 - val_loss: 0.7234 - val_accuracy: 0.5741\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7345 - accuracy: 0.5962 - val_loss: 0.7207 - val_accuracy: 0.5741\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7319 - accuracy: 0.5962 - val_loss: 0.7180 - val_accuracy: 0.5556\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7292 - accuracy: 0.5962 - val_loss: 0.7155 - val_accuracy: 0.5556\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7270 - accuracy: 0.5915 - val_loss: 0.7128 - val_accuracy: 0.5556\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7246 - accuracy: 0.5869 - val_loss: 0.7104 - val_accuracy: 0.5556\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7224 - accuracy: 0.5869 - val_loss: 0.7083 - val_accuracy: 0.5556\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7203 - accuracy: 0.5915 - val_loss: 0.7062 - val_accuracy: 0.5556\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.5915 - val_loss: 0.7044 - val_accuracy: 0.5556\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7166 - accuracy: 0.5915 - val_loss: 0.7026 - val_accuracy: 0.5556\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.5915 - val_loss: 0.7009 - val_accuracy: 0.5741\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7134 - accuracy: 0.5915 - val_loss: 0.6992 - val_accuracy: 0.5741\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7119 - accuracy: 0.5915 - val_loss: 0.6977 - val_accuracy: 0.5741\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.5822 - val_loss: 0.6964 - val_accuracy: 0.5556\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7092 - accuracy: 0.5869 - val_loss: 0.6952 - val_accuracy: 0.5741\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.5915 - val_loss: 0.6940 - val_accuracy: 0.5741\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7070 - accuracy: 0.5915 - val_loss: 0.6929 - val_accuracy: 0.5741\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.5915 - val_loss: 0.6919 - val_accuracy: 0.5741\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.5822 - val_loss: 0.6909 - val_accuracy: 0.5741\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7039 - accuracy: 0.5822 - val_loss: 0.6899 - val_accuracy: 0.5741\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.5822 - val_loss: 0.6889 - val_accuracy: 0.5741\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7020 - accuracy: 0.5822 - val_loss: 0.6881 - val_accuracy: 0.5741\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.5822 - val_loss: 0.6873 - val_accuracy: 0.5741\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7004 - accuracy: 0.5822 - val_loss: 0.6865 - val_accuracy: 0.5741\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6998 - accuracy: 0.5775 - val_loss: 0.6858 - val_accuracy: 0.5741\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.5822 - val_loss: 0.6850 - val_accuracy: 0.5741\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.5822 - val_loss: 0.6843 - val_accuracy: 0.5741\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.5822 - val_loss: 0.6836 - val_accuracy: 0.5741\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.5822 - val_loss: 0.6831 - val_accuracy: 0.5741\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.5869 - val_loss: 0.6825 - val_accuracy: 0.5741\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.5869 - val_loss: 0.6819 - val_accuracy: 0.5741\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6955 - accuracy: 0.5869 - val_loss: 0.6813 - val_accuracy: 0.5741\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.5915 - val_loss: 0.6808 - val_accuracy: 0.5741\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5962 - val_loss: 0.6801 - val_accuracy: 0.5741\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5962 - val_loss: 0.6795 - val_accuracy: 0.5741\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6009 - val_loss: 0.6789 - val_accuracy: 0.5741\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.6009 - val_loss: 0.6783 - val_accuracy: 0.5741\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.6056 - val_loss: 0.6777 - val_accuracy: 0.5741\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.6056 - val_loss: 0.6771 - val_accuracy: 0.5926\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.6103 - val_loss: 0.6765 - val_accuracy: 0.5926\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.6103 - val_loss: 0.6760 - val_accuracy: 0.6111\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6103 - val_loss: 0.6754 - val_accuracy: 0.6111\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.6103 - val_loss: 0.6750 - val_accuracy: 0.6111\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.6056 - val_loss: 0.6744 - val_accuracy: 0.6111\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.6056 - val_loss: 0.6739 - val_accuracy: 0.6111\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.6103 - val_loss: 0.6734 - val_accuracy: 0.6111\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6886 - accuracy: 0.6103 - val_loss: 0.6730 - val_accuracy: 0.6111\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.6056 - val_loss: 0.6726 - val_accuracy: 0.6111\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.6056 - val_loss: 0.6720 - val_accuracy: 0.6111\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6874 - accuracy: 0.6056 - val_loss: 0.6715 - val_accuracy: 0.6111\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.6056 - val_loss: 0.6710 - val_accuracy: 0.5926\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.6056 - val_loss: 0.6705 - val_accuracy: 0.5926\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.6056 - val_loss: 0.6700 - val_accuracy: 0.5926\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.6009 - val_loss: 0.6695 - val_accuracy: 0.5926\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.6009 - val_loss: 0.6691 - val_accuracy: 0.5926\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.6056 - val_loss: 0.6685 - val_accuracy: 0.5926\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.6103 - val_loss: 0.6681 - val_accuracy: 0.5926\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.6103 - val_loss: 0.6675 - val_accuracy: 0.5926\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.6150 - val_loss: 0.6669 - val_accuracy: 0.5926\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.6197 - val_loss: 0.6666 - val_accuracy: 0.5926\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.6197 - val_loss: 0.6661 - val_accuracy: 0.5926\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.6197 - val_loss: 0.6657 - val_accuracy: 0.5926\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.6244 - val_loss: 0.6654 - val_accuracy: 0.5926\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.6244 - val_loss: 0.6649 - val_accuracy: 0.5926\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6822 - accuracy: 0.6291 - val_loss: 0.6646 - val_accuracy: 0.5926\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.6291 - val_loss: 0.6643 - val_accuracy: 0.5926\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.6291 - val_loss: 0.6638 - val_accuracy: 0.5741\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.6291 - val_loss: 0.6635 - val_accuracy: 0.5741\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.6291 - val_loss: 0.6632 - val_accuracy: 0.5741\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6808 - accuracy: 0.6291 - val_loss: 0.6629 - val_accuracy: 0.5556\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.6291 - val_loss: 0.6627 - val_accuracy: 0.5556\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.6291 - val_loss: 0.6624 - val_accuracy: 0.5556\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.6291 - val_loss: 0.6620 - val_accuracy: 0.5556\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.6244 - val_loss: 0.6618 - val_accuracy: 0.5556\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.6244 - val_loss: 0.6615 - val_accuracy: 0.5556\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.6244 - val_loss: 0.6612 - val_accuracy: 0.5556\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6789 - accuracy: 0.6244 - val_loss: 0.6609 - val_accuracy: 0.5556\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.6244 - val_loss: 0.6605 - val_accuracy: 0.5556\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.6244 - val_loss: 0.6603 - val_accuracy: 0.5556\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6782 - accuracy: 0.6244 - val_loss: 0.6600 - val_accuracy: 0.5556\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.6244 - val_loss: 0.6597 - val_accuracy: 0.5556\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6777 - accuracy: 0.6244 - val_loss: 0.6595 - val_accuracy: 0.5556\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.6244 - val_loss: 0.6592 - val_accuracy: 0.5556\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.6244 - val_loss: 0.6589 - val_accuracy: 0.5556\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6771 - accuracy: 0.6244 - val_loss: 0.6586 - val_accuracy: 0.5741\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.6244 - val_loss: 0.6583 - val_accuracy: 0.5741\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.6244 - val_loss: 0.6581 - val_accuracy: 0.5741\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.6244 - val_loss: 0.6578 - val_accuracy: 0.5741\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.6244 - val_loss: 0.6575 - val_accuracy: 0.5741\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6761 - accuracy: 0.6244 - val_loss: 0.6573 - val_accuracy: 0.5741\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.6244 - val_loss: 0.6570 - val_accuracy: 0.5741\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.6244 - val_loss: 0.6567 - val_accuracy: 0.5741\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6244 - val_loss: 0.6565 - val_accuracy: 0.5741\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.6244 - val_loss: 0.6563 - val_accuracy: 0.5741\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.6244 - val_loss: 0.6561 - val_accuracy: 0.5741\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.6244 - val_loss: 0.6559 - val_accuracy: 0.5741\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.6244 - val_loss: 0.6557 - val_accuracy: 0.5741\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.6244 - val_loss: 0.6554 - val_accuracy: 0.5741\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.6244 - val_loss: 0.6552 - val_accuracy: 0.5741\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6741 - accuracy: 0.6244 - val_loss: 0.6550 - val_accuracy: 0.5741\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6244 - val_loss: 0.6548 - val_accuracy: 0.5741\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6737 - accuracy: 0.6244 - val_loss: 0.6546 - val_accuracy: 0.5741\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.6244 - val_loss: 0.6544 - val_accuracy: 0.5741\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.6244 - val_loss: 0.6543 - val_accuracy: 0.5926\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.6244 - val_loss: 0.6541 - val_accuracy: 0.5926\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6244 - val_loss: 0.6540 - val_accuracy: 0.5926\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.6244 - val_loss: 0.6538 - val_accuracy: 0.5926\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.6197 - val_loss: 0.6536 - val_accuracy: 0.5741\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.6197 - val_loss: 0.6534 - val_accuracy: 0.5741\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6244 - val_loss: 0.6533 - val_accuracy: 0.5556\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6244 - val_loss: 0.6531 - val_accuracy: 0.5556\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.6197 - val_loss: 0.6530 - val_accuracy: 0.5926\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.6197 - val_loss: 0.6528 - val_accuracy: 0.5741\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.6197 - val_loss: 0.6527 - val_accuracy: 0.5926\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.6291 - val_loss: 0.6525 - val_accuracy: 0.5741\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.6291 - val_loss: 0.6523 - val_accuracy: 0.5741\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6711 - accuracy: 0.6291 - val_loss: 0.6521 - val_accuracy: 0.5741\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.6291 - val_loss: 0.6520 - val_accuracy: 0.5741\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6291 - val_loss: 0.6519 - val_accuracy: 0.5926\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6706 - accuracy: 0.6291 - val_loss: 0.6518 - val_accuracy: 0.5741\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.6291 - val_loss: 0.6517 - val_accuracy: 0.5741\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6703 - accuracy: 0.6291 - val_loss: 0.6515 - val_accuracy: 0.5741\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.6291 - val_loss: 0.6515 - val_accuracy: 0.5741\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.6291 - val_loss: 0.6513 - val_accuracy: 0.5926\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6699 - accuracy: 0.6291 - val_loss: 0.6512 - val_accuracy: 0.5741\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.6291 - val_loss: 0.6511 - val_accuracy: 0.5741\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6695 - accuracy: 0.6291 - val_loss: 0.6510 - val_accuracy: 0.5741\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.6291 - val_loss: 0.6508 - val_accuracy: 0.5741\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.6291 - val_loss: 0.6507 - val_accuracy: 0.5741\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.6291 - val_loss: 0.6505 - val_accuracy: 0.5741\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.6291 - val_loss: 0.6504 - val_accuracy: 0.5741\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6684 - accuracy: 0.6291 - val_loss: 0.6503 - val_accuracy: 0.5926\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.6291 - val_loss: 0.6502 - val_accuracy: 0.5926\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.6291 - val_loss: 0.6501 - val_accuracy: 0.5926\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.6244 - val_loss: 0.6500 - val_accuracy: 0.5926\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.6244 - val_loss: 0.6499 - val_accuracy: 0.5926\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6673 - accuracy: 0.6244 - val_loss: 0.6498 - val_accuracy: 0.5741\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6291 - val_loss: 0.6496 - val_accuracy: 0.5741\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.6291 - val_loss: 0.6495 - val_accuracy: 0.5741\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6667 - accuracy: 0.6291 - val_loss: 0.6494 - val_accuracy: 0.5741\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6291 - val_loss: 0.6494 - val_accuracy: 0.5741\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6662 - accuracy: 0.6291 - val_loss: 0.6493 - val_accuracy: 0.5741\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.6338 - val_loss: 0.6492 - val_accuracy: 0.5741\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.6291 - val_loss: 0.6492 - val_accuracy: 0.5741\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6656 - accuracy: 0.6291 - val_loss: 0.6489 - val_accuracy: 0.5741\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.6291 - val_loss: 0.6489 - val_accuracy: 0.5741\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.6291 - val_loss: 0.6488 - val_accuracy: 0.5741\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.6291 - val_loss: 0.6486 - val_accuracy: 0.5741\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.6291 - val_loss: 0.6486 - val_accuracy: 0.5741\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.6338 - val_loss: 0.6484 - val_accuracy: 0.5926\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.6338 - val_loss: 0.6484 - val_accuracy: 0.5926\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6640 - accuracy: 0.6291 - val_loss: 0.6482 - val_accuracy: 0.5926\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.6338 - val_loss: 0.6481 - val_accuracy: 0.5926\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6244 - val_loss: 0.6480 - val_accuracy: 0.5926\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.6244 - val_loss: 0.6479 - val_accuracy: 0.5926\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6291 - val_loss: 0.6478 - val_accuracy: 0.5926\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.6244 - val_loss: 0.6476 - val_accuracy: 0.5926\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.6244 - val_loss: 0.6475 - val_accuracy: 0.5926\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6291 - val_loss: 0.6473 - val_accuracy: 0.5926\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.6244 - val_loss: 0.6472 - val_accuracy: 0.5926\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.6291 - val_loss: 0.6471 - val_accuracy: 0.5926\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6621 - accuracy: 0.6338 - val_loss: 0.6470 - val_accuracy: 0.5926\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.6338 - val_loss: 0.6470 - val_accuracy: 0.5926\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6338 - val_loss: 0.6469 - val_accuracy: 0.5926\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.6385 - val_loss: 0.6467 - val_accuracy: 0.5926\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.6385 - val_loss: 0.6466 - val_accuracy: 0.5926\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6613 - accuracy: 0.6385 - val_loss: 0.6465 - val_accuracy: 0.5926\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6385 - val_loss: 0.6463 - val_accuracy: 0.5926\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6385 - val_loss: 0.6461 - val_accuracy: 0.5926\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6609 - accuracy: 0.6385 - val_loss: 0.6460 - val_accuracy: 0.5926\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6432 - val_loss: 0.6459 - val_accuracy: 0.5926\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6605 - accuracy: 0.6432 - val_loss: 0.6458 - val_accuracy: 0.5926\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.6432 - val_loss: 0.6457 - val_accuracy: 0.5926\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6432 - val_loss: 0.6455 - val_accuracy: 0.5926\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.6385 - val_loss: 0.6454 - val_accuracy: 0.5926\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.6385 - val_loss: 0.6452 - val_accuracy: 0.5926\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.6385 - val_loss: 0.6451 - val_accuracy: 0.5926\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6385 - val_loss: 0.6450 - val_accuracy: 0.5926\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6385 - val_loss: 0.6450 - val_accuracy: 0.5926\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.6385 - val_loss: 0.6449 - val_accuracy: 0.5926\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.6385 - val_loss: 0.6448 - val_accuracy: 0.5926\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6591 - accuracy: 0.6385 - val_loss: 0.6446 - val_accuracy: 0.5926\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.6338 - val_loss: 0.6445 - val_accuracy: 0.5926\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.6385 - val_loss: 0.6443 - val_accuracy: 0.5926\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6586 - accuracy: 0.6338 - val_loss: 0.6443 - val_accuracy: 0.5926\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.6338 - val_loss: 0.6441 - val_accuracy: 0.5926\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6583 - accuracy: 0.6338 - val_loss: 0.6439 - val_accuracy: 0.5926\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6291 - val_loss: 0.6438 - val_accuracy: 0.5926\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6291 - val_loss: 0.6438 - val_accuracy: 0.5926\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.6291 - val_loss: 0.6437 - val_accuracy: 0.5926\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.6291 - val_loss: 0.6436 - val_accuracy: 0.5926\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6576 - accuracy: 0.6291 - val_loss: 0.6435 - val_accuracy: 0.5926\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.6291 - val_loss: 0.6435 - val_accuracy: 0.5926\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.6291 - val_loss: 0.6435 - val_accuracy: 0.5926\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6291 - val_loss: 0.6434 - val_accuracy: 0.5926\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.6291 - val_loss: 0.6433 - val_accuracy: 0.5926\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.6291 - val_loss: 0.6432 - val_accuracy: 0.5926\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.6291 - val_loss: 0.6431 - val_accuracy: 0.5926\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.6291 - val_loss: 0.6430 - val_accuracy: 0.5926\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6565 - accuracy: 0.6291 - val_loss: 0.6431 - val_accuracy: 0.5926\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6338 - val_loss: 0.6430 - val_accuracy: 0.5926\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6560 - accuracy: 0.6291 - val_loss: 0.6428 - val_accuracy: 0.5926\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6291 - val_loss: 0.6428 - val_accuracy: 0.5926\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6291 - val_loss: 0.6426 - val_accuracy: 0.5926\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6556 - accuracy: 0.6291 - val_loss: 0.6426 - val_accuracy: 0.5926\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.6244 - val_loss: 0.6425 - val_accuracy: 0.5926\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6554 - accuracy: 0.6244 - val_loss: 0.6425 - val_accuracy: 0.5926\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6244 - val_loss: 0.6423 - val_accuracy: 0.5926\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6244 - val_loss: 0.6423 - val_accuracy: 0.5926\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6550 - accuracy: 0.6244 - val_loss: 0.6422 - val_accuracy: 0.5926\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.6244 - val_loss: 0.6423 - val_accuracy: 0.5926\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.6244 - val_loss: 0.6423 - val_accuracy: 0.5926\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6244 - val_loss: 0.6422 - val_accuracy: 0.5926\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6244 - val_loss: 0.6422 - val_accuracy: 0.5926\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.6244 - val_loss: 0.6421 - val_accuracy: 0.5926\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.6244 - val_loss: 0.6421 - val_accuracy: 0.5926\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6244 - val_loss: 0.6421 - val_accuracy: 0.5926\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6244 - val_loss: 0.6420 - val_accuracy: 0.5926\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6244 - val_loss: 0.6419 - val_accuracy: 0.5926\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6538 - accuracy: 0.6244 - val_loss: 0.6418 - val_accuracy: 0.5926\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6244 - val_loss: 0.6418 - val_accuracy: 0.5926\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6535 - accuracy: 0.6291 - val_loss: 0.6417 - val_accuracy: 0.5926\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6291 - val_loss: 0.6416 - val_accuracy: 0.5926\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.6291 - val_loss: 0.6416 - val_accuracy: 0.5926\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.6291 - val_loss: 0.6416 - val_accuracy: 0.5926\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6291 - val_loss: 0.6415 - val_accuracy: 0.5926\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6530 - accuracy: 0.6291 - val_loss: 0.6415 - val_accuracy: 0.5926\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6291 - val_loss: 0.6415 - val_accuracy: 0.5926\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.6244 - val_loss: 0.6415 - val_accuracy: 0.5926\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 0.6244 - val_loss: 0.6415 - val_accuracy: 0.5926\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6244 - val_loss: 0.6416 - val_accuracy: 0.5926\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6525 - accuracy: 0.6244 - val_loss: 0.6415 - val_accuracy: 0.5926\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6244 - val_loss: 0.6414 - val_accuracy: 0.5926\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6291 - val_loss: 0.6415 - val_accuracy: 0.6296\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.6338 - val_loss: 0.6414 - val_accuracy: 0.6296\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6338 - val_loss: 0.6414 - val_accuracy: 0.6296\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6338 - val_loss: 0.6414 - val_accuracy: 0.6296\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6338 - val_loss: 0.6413 - val_accuracy: 0.6296\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6338 - val_loss: 0.6412 - val_accuracy: 0.6296\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.6291 - val_loss: 0.6411 - val_accuracy: 0.6296\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.6244 - val_loss: 0.6411 - val_accuracy: 0.6296\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.6244 - val_loss: 0.6410 - val_accuracy: 0.6296\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6244 - val_loss: 0.6411 - val_accuracy: 0.6296\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6291 - val_loss: 0.6411 - val_accuracy: 0.6296\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6291 - val_loss: 0.6410 - val_accuracy: 0.6296\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6338 - val_loss: 0.6409 - val_accuracy: 0.6296\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.6338 - val_loss: 0.6409 - val_accuracy: 0.6296\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6338 - val_loss: 0.6409 - val_accuracy: 0.6296\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6338 - val_loss: 0.6408 - val_accuracy: 0.6296\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6506 - accuracy: 0.6338 - val_loss: 0.6406 - val_accuracy: 0.6296\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.6291 - val_loss: 0.6405 - val_accuracy: 0.6296\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.6291 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6291 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6244 - val_loss: 0.6403 - val_accuracy: 0.6296\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6501 - accuracy: 0.6291 - val_loss: 0.6403 - val_accuracy: 0.6296\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.6291 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.6291 - val_loss: 0.6403 - val_accuracy: 0.6296\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6291 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6338 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.6338 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6338 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.6338 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6338 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6338 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6492 - accuracy: 0.6338 - val_loss: 0.6404 - val_accuracy: 0.6296\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6338 - val_loss: 0.6402 - val_accuracy: 0.6296\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.6338 - val_loss: 0.6402 - val_accuracy: 0.6296\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6338 - val_loss: 0.6402 - val_accuracy: 0.6296\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6338 - val_loss: 0.6401 - val_accuracy: 0.6296\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6488 - accuracy: 0.6338 - val_loss: 0.6401 - val_accuracy: 0.6296\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6338 - val_loss: 0.6401 - val_accuracy: 0.6296\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.6338 - val_loss: 0.6401 - val_accuracy: 0.6296\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.6338 - val_loss: 0.6400 - val_accuracy: 0.6296\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6338 - val_loss: 0.6400 - val_accuracy: 0.6296\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.6338 - val_loss: 0.6399 - val_accuracy: 0.6296\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6291 - val_loss: 0.6398 - val_accuracy: 0.6296\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.6291 - val_loss: 0.6398 - val_accuracy: 0.6296\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6291 - val_loss: 0.6398 - val_accuracy: 0.6296\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6338 - val_loss: 0.6398 - val_accuracy: 0.6296\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.6338 - val_loss: 0.6397 - val_accuracy: 0.6296\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6338 - val_loss: 0.6397 - val_accuracy: 0.6296\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6338 - val_loss: 0.6397 - val_accuracy: 0.6296\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6338 - val_loss: 0.6397 - val_accuracy: 0.6296\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6338 - val_loss: 0.6397 - val_accuracy: 0.6296\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6338 - val_loss: 0.6397 - val_accuracy: 0.6296\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6291 - val_loss: 0.6396 - val_accuracy: 0.6296\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.6291 - val_loss: 0.6396 - val_accuracy: 0.6296\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6244 - val_loss: 0.6394 - val_accuracy: 0.6296\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6244 - val_loss: 0.6394 - val_accuracy: 0.6296\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6472 - accuracy: 0.6244 - val_loss: 0.6393 - val_accuracy: 0.6296\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.6244 - val_loss: 0.6393 - val_accuracy: 0.6296\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6471 - accuracy: 0.6291 - val_loss: 0.6392 - val_accuracy: 0.6296\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6244 - val_loss: 0.6392 - val_accuracy: 0.6296\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6291 - val_loss: 0.6392 - val_accuracy: 0.6296\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.6291 - val_loss: 0.6392 - val_accuracy: 0.6296\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6338 - val_loss: 0.6393 - val_accuracy: 0.6296\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6291 - val_loss: 0.6392 - val_accuracy: 0.6296\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6385 - val_loss: 0.6394 - val_accuracy: 0.6296\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6385 - val_loss: 0.6393 - val_accuracy: 0.6296\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.6338 - val_loss: 0.6392 - val_accuracy: 0.6296\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6338 - val_loss: 0.6392 - val_accuracy: 0.6296\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.6291 - val_loss: 0.6392 - val_accuracy: 0.6481\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6291 - val_loss: 0.6392 - val_accuracy: 0.6481\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6244 - val_loss: 0.6392 - val_accuracy: 0.6481\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6461 - accuracy: 0.6244 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6244 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6460 - accuracy: 0.6291 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6244 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6244 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6458 - accuracy: 0.6244 - val_loss: 0.6392 - val_accuracy: 0.6481\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6244 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.6291 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6291 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6291 - val_loss: 0.6391 - val_accuracy: 0.6481\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6244 - val_loss: 0.6390 - val_accuracy: 0.6481\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6244 - val_loss: 0.6389 - val_accuracy: 0.6481\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.6244 - val_loss: 0.6389 - val_accuracy: 0.6481\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6244 - val_loss: 0.6388 - val_accuracy: 0.6481\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6244 - val_loss: 0.6388 - val_accuracy: 0.6481\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6450 - accuracy: 0.6244 - val_loss: 0.6387 - val_accuracy: 0.6481\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6244 - val_loss: 0.6387 - val_accuracy: 0.6481\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6450 - accuracy: 0.6244 - val_loss: 0.6387 - val_accuracy: 0.6481\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6244 - val_loss: 0.6386 - val_accuracy: 0.6481\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.6197 - val_loss: 0.6386 - val_accuracy: 0.6296\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6447 - accuracy: 0.6197 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.6197 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6445 - accuracy: 0.6197 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6442 - accuracy: 0.6197 - val_loss: 0.6382 - val_accuracy: 0.6296\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6440 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6481\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6481\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6438 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6481\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.6197 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6197 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.6197 - val_loss: 0.6385 - val_accuracy: 0.6296\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6432 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6197 - val_loss: 0.6384 - val_accuracy: 0.6296\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6426 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6197 - val_loss: 0.6383 - val_accuracy: 0.6296\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.6197 - val_loss: 0.6382 - val_accuracy: 0.6296\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6197 - val_loss: 0.6382 - val_accuracy: 0.6296\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6197 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.6197 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.6197 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.6197 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6197 - val_loss: 0.6379 - val_accuracy: 0.6296\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6197 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.6197 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6197 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6415 - accuracy: 0.6197 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6244 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6244 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.6244 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6244 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.6244 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6244 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6244 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6291 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6291 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6410 - accuracy: 0.6291 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6291 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6291 - val_loss: 0.6382 - val_accuracy: 0.6296\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6291 - val_loss: 0.6382 - val_accuracy: 0.6296\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6291 - val_loss: 0.6382 - val_accuracy: 0.6296\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.6291 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6291 - val_loss: 0.6381 - val_accuracy: 0.6296\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.6291 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.6291 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6291 - val_loss: 0.6380 - val_accuracy: 0.6296\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.6244 - val_loss: 0.6379 - val_accuracy: 0.6296\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6244 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6404 - accuracy: 0.6291 - val_loss: 0.6379 - val_accuracy: 0.6296\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6403 - accuracy: 0.6244 - val_loss: 0.6379 - val_accuracy: 0.6296\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6291 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.6244 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6244 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6244 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6401 - accuracy: 0.6291 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6291 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6399 - accuracy: 0.6291 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6291 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6291 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6291 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6291 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6291 - val_loss: 0.6372 - val_accuracy: 0.6296\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.6291 - val_loss: 0.6372 - val_accuracy: 0.6296\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6390 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6291 - val_loss: 0.6372 - val_accuracy: 0.6296\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6291 - val_loss: 0.6372 - val_accuracy: 0.6296\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6244 - val_loss: 0.6372 - val_accuracy: 0.6296\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.6244 - val_loss: 0.6371 - val_accuracy: 0.6296\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6244 - val_loss: 0.6372 - val_accuracy: 0.6296\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6244 - val_loss: 0.6372 - val_accuracy: 0.6296\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6244 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.6291 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6373 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6372 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6244 - val_loss: 0.6373 - val_accuracy: 0.6296\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6372 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6370 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6291 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6369 - accuracy: 0.6244 - val_loss: 0.6374 - val_accuracy: 0.6296\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6244 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6291 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6244 - val_loss: 0.6375 - val_accuracy: 0.6296\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6244 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6244 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6244 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6364 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.6291 - val_loss: 0.6377 - val_accuracy: 0.6296\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6291 - val_loss: 0.6378 - val_accuracy: 0.6296\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.6291 - val_loss: 0.6378 - val_accuracy: 0.6296\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, callbacks= checkpoint, batch_size= 32, epochs= 500, validation_data= (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b44a214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAw+UlEQVR4nO3dd3hc1Z3/8fdXvfdeLBe5V7DAtNAMwRBKChAT0gshCSmbLAQ2/ZfsZrPZZNMgBAgQAoElQBaSEAMBbIoBWwbjiovcJFuyitW7NOf3xx0ZWYyMbGs0Kp/X88wzM3fuzHyvHpiPzzn3nmPOOURERAYKC3UBIiIyOikgREQkIAWEiIgEpIAQEZGAFBAiIhJQRKgLGE4ZGRlu8uTJoS5DRGTMWLduXa1zLjPQa+MqICZPnkxpaWmoyxARGTPMbO9gr6mLSUREAlJAiIhIQAoIEREJSAEhIiIBKSBERCQgBYSIiASkgBARkYAmfED4fI7fPLeDF7bXhLoUEZFRZcIHRFiYcccLu3jurepQlyIiMqpM+IAAyEmOobKxPdRliIiMKgoIIDsphqqmzlCXISIyqigggNzkGKrUghAROYICAshJiqGmuZOeXl+oSxERGTUUEEBOciw+BzUt6mYSEemjgABykqMBqGrsCHElIiKjhwICyEmKBRQQIiL9KSDwTnMFqGpSQIiI9FFAAKlxkURFhKkFISLST1ADwsyWmdk2M9tpZjcHeP1GM1vvv20ys14zS+v3eriZvWFmfwtyneQkxagFISLST9ACwszCgVuBi4E5wDVmNqf/Ps65nzrnFjnnFgG3AKucc4f67fJVYGuwauwvJymGSrUgREQOC2YL4lRgp3Nul3OuC3gIuOIo+18DPNj3xMwKgPcBdwWxxsNykmM4qBaEiMhhwQyIfKC83/MK/7Z3MLM4YBnwaL/NvwBuAo569ZqZXWdmpWZWWlNz/DOy5iTHUNXYgXPuuD9DRGQ8CWZAWIBtg/36Xga83Ne9ZGaXAtXOuXXv9iXOuTuccyXOuZLMzMzjLjYnKYbOHh8Nbd3H/RkiIuNJMAOiAijs97wAODDIvsvp170EnAlcbmZ78Lqmzjez+4NRZB+d6ioicqRgBsRaYLqZTTGzKLwQeGLgTmaWDJwDPN63zTl3i3OuwDk32f++55xzHw1irW8HhAaqRUQAiAjWBzvneszsBuApIBy42zm32cyu979+u3/XDwBPO+dag1XLUOT6A+KAZnUVEQGCGBAAzrkngScHbLt9wPN7gXuP8hkrgZXDXtwAWYkxRIYb++sVECIioCupDwsPM/JSYqlQQIiIAAqIIxSkxlJR3xbqMkRERgUFRD/5akGIiBymgOinIDWO6uZOOrp7Q12KiEjIKSCcg32vQu1OClK9dSEONKgVISKigAC47wpYdw8FqXEA6mYSEUEBAWaQkA0tBw+3IBQQIiIKCE9iDjRXkZ0UQ0SY6UwmEREUEB5/C0LXQoiIvE0BAf4WxEFA10KIiPRRQIDXguhshO52f0CoBSEiooAASMz17purdC2EiIifAgIgMdu773cm035dCyEiE5wCAiAhx7tvrqQo3bsWYm9dSGcfFxEJOQUEeIPUAM0HmZaZAEBZtQJCRCY2BQRAbBqERUBLFSlxUWQkRLGzuiXUVYmIhJQCAiAszDuTyX+q69TMBMpqFBAiMrEpIPokZENLFQDFWQnsrGnBORfiokREQkcB0ScpDxr3AzAtM4GGtm4OtXaFuCgRkdBRQPRJmQSNFeAc0zLjASir0UC1iExcCog+yQXQ3Qrt9RRneWcyaaBaRCYyBUSf5ELvvmEfecmxxEaGa6BaRCY0BUSfFH9ANFYQFmZMzYxXQIjIhKaA6NPXgmgsB7yBanUxichEpoDoE5cOEbHeQDVeQOxvaKe9S5P2icjEpIDoY+Z1MzXsA7xrIZyDXbVqRYjIxBTUgDCzZWa2zcx2mtnNAV6/0czW+2+bzKzXzNLMrNDMnjezrWa22cy+Gsw6D0sueLuLKUunuorIxBa0gDCzcOBW4GJgDnCNmc3pv49z7qfOuUXOuUXALcAq59whoAf4hnNuNnAa8KWB7w2K5MLDXUyT0+MJMyjTOISITFDBbEGcCux0zu1yznUBDwFXHGX/a4AHAZxzlc651/2Pm4GtQH4Qa/WkFEJrDXS1EhMZTmFaHDt1JpOITFDBDIh8oLzf8woG+ZE3szhgGfBogNcmAycBrw3y3uvMrNTMSmtqak6s4tQp3r1/HGJaZoJaECIyYQUzICzAtsFmv7sMeNnfvfT2B5gl4IXG15xzTYHe6Jy7wzlX4pwryczMPKGCSSny7uv3AjAtM57dta30+jRpn4hMPMEMiAqgsN/zAuDAIPsux9+91MfMIvHC4QHn3GNBqXCgVH9ANHgBUZyVQGePj/31Wn5URCaeYAbEWmC6mU0xsyi8EHhi4E5mlgycAzzeb5sBvwe2Oud+HsQajxSfCZFxh1sQxVmJAGw72DxiJYiIjBZBCwjnXA9wA/AU3iDzw865zWZ2vZld32/XDwBPO+f6n096JvAx4Px+p8FeEqxaDzPzupnq9wAwJzeJMION+xuD/tUiIqNNRDA/3Dn3JPDkgG23D3h+L3DvgG0vEXgMI/hSiw53McVGhVOclcDGioaQlCIiEkq6knqglCKvi8m/mtz8/BQ27m/S6nIiMuEoIAZKnQxdzdBeD8D8/CRqWzqpauoIbV0iIiNMATFQ35lM9bsBmF+QAsDGCo1DiMjEooAYaMC1EHNykwgPM9aXN4SuJhGREFBADDTgWojYqHDm5iVRurc+hEWJiIw8BcRA0Yne2hD+FgRASVEab5Y30NXjC2FhIiIjSwERSL9rIQBKJqfS2eNj0wGNQ4jIxKGACCRtyuFBaoCSolQA1u1RN5OITBwKiEDSi70ZXXs6AchKimFSWhxr9xx6lzeKiIwfCohA0ovB+d7RzbRub70umBORCUMBEUj6NO++dsfhTSVFadS1drG7VkuQisjEoIAIJL3Yu6/beXjTqVPSAHh1l7qZRGRiUEAEEpMM8VlHBMS0zHhyk2N4aecJrlonIjJGKCAGk158RECYGe+ZnsHLO+u0wpyITAgKiMFkHBkQAGdNz6SxvVvrQ4jIhKCAGEz6dGitgba3xxzOKs7ADFZuqw5hYSIiI0MBMZisOd599dbDm9LioygpSmXFpqoQFSUiMnIUEIPJ7guILUdsvmR+Lm9VNet0VxEZ9xQQg0nMhZgUOLj5iM3nz8oC4MUdOptJRMY3BcRgzCB77jtaEEXp8UxKi+P5tzQOISLjmwLiaLJme2MQA6bXuHheDi/uqKW2pTNEhYmIBJ8C4miy5kBnEzSWH7H5Q4sL6PE5Hl9/IESFiYgEnwLiaLLnefdVm47YPCM7kQUFyTy6riIERYmIjAwFxNHkzAcLg8r173jpysUFbKlsYrMWERKRcUoBcTRRcZAxEw6sf8dLly3IIyo8jEfX7R/5ukRERoAC4t3knQQH3njHQHVqfBRLZ2fx+Pr9dPdqrWoRGX8UEO8mbxG0VkNz5TteunJxAXWtXazcpmsiRGT8CWpAmNkyM9tmZjvN7OYAr99oZuv9t01m1mtmaUN574jJXeTdB+hmOntGJhkJ0TxcWv6O10RExrqgBYSZhQO3AhcDc4BrzGxO/32ccz91zi1yzi0CbgFWOecODeW9I6ZvoPrAG+94KTI8jA+fUsA/tx7U1BsiMu4EswVxKrDTObfLOdcFPARccZT9rwEePM73Bk9UHGTOCngmE8Anz5hCZHgYd7xQNrJ1iYgEWTADIh/o3/dS4d/2DmYWBywDHj2O915nZqVmVlpTE6SxgNxFAQeqATITo7lqcQGPrttPdVNHcL5fRCQEghkQFmDbYEuxXQa87JzrW3xhyO91zt3hnCtxzpVkZmYeR5lDkHeStzZEY+CxhuvOnkqPz8edL+4KzveLiIRAMAOiAijs97wAGGxuiuW83b10rO8NvqLTvfu9rwR+OT2e9y/K575X9lLVqFaEiIwPwQyItcB0M5tiZlF4IfDEwJ3MLBk4B3j8WN87YrLmQEwy7H150F3+5cIZ+Jzjl89uH8HCRESCJ2gB4ZzrAW4AngK2Ag875zab2fVmdn2/XT8APO2ca3239war1ncVFg6TTj9qQBSmxXHtkiIeLq2grKZlBIsTEQkOcwEGXseqkpISV1paGpwPf/lX8Mx34BvbITE74C41zZ2c998rObkolT986hTMAg2liIiMHma2zjlXEug1XUk9VEVnevd7Xhx0l8zEaP71vTN4YXsNT7ypqcBFZGwbUkCYWbyZhfkfzzCzy80sMriljTJ5iyA2DXY8c9TdPnb6ZBYWpvDDv22hsa17ZGoTEQmCobYgXgBizCwfeBb4FHBvsIoalcLCofgC2PkM+AafnC88zPjxB+ZT39bNfzy5dQQLFBEZXkMNCHPOtQEfBH7tnPsA3hQYE8v090JbHRx4/ai7zclL4vNnT+V/S8u1qJCIjFlDDggzOx24Fvi7f1tEcEoaxYqXevMy7Xj6XXf9+oUzOGVyKj/6+xbqW7tGoDgRkeE11ID4Gt5ken/xn6o6FXg+aFWNVnFpUHDKkAIiIjyMH75/Hk0dPepqEpExaUgB4Zxb5Zy73Dn3E/9gda1z7itBrm10mn6hNy9Tc9W77jorx+tq+vO6ClZsevf9RURGk6GexfQnM0sys3hgC7DNzG4Mbmmj1OzLvftNjw1p969dMIP5+cnc/NgGTcMhImPKULuY5jjnmoD3A08Ck4CPBauoUS1zJuQuhI0PD2n3qIgwfrl8EZ3dPr7+8Hp8vvFzYaKIjG9DDYhI/3UP7wced851M/jMrOPf/Ku9bqbaHUPafWpmAt+/fA6ry+r47SqtGyEiY8NQA+J3wB4gHnjBzIqApmAVNerN+5B3NtOGobUiAK4uKeTSBbn89KltuspaRMaEoQ5S/8o5l++cu8R59gLnBbm20SspF6ac7XUzDXEuKzPjZ1cv5NTJadz0yJtsPtAY5CJFRE7MUAepk83s530rt5nZz/BaExPXgg9D/R6oWDvkt0RHhHPrtSeTGhfFZ+4tpbKxPXj1iYicoKF2Md0NNANX+29NwD3BKmpMmHUpRMTAhv89prdlJkZz9ydPoaWzh0/evZamDs3XJCKj01ADYppz7nvOuV3+2w+AqcEsbNSLSYKZl3inu/Ye24/87NwkfvexxZTVtHD9H9fR1TP43E4iIqEy1IBoN7Oz+p6Y2ZmA+kcWLof2Q7D1r8f81jOLM/ivKxewuqyOmx55k/G0LoeIjA9DnU/peuA+//KgAPXAJ4JT0hhSfAGkToFXb4N5Hzzmt3/w5AIqGzv46VPbyEuJ5aZls4JQpIjI8RnqWUxvOucWAguABc65k4Dzg1rZWBAWDqd9wRuoLl9zXB/xxXOncc2pk7htZRn3v7p3mAsUETl+x7SinHOuyX9FNcDXg1DP2LPoWohOhlduPa63mxk/vGIu58/K4juPb+LBNfuGuUARkeNzIkuOasFlgOgEWPwJ2PoENBzfj3tEeBi3fuRkzpmRybf+spHnt1UPc5EiIsfuRAJCo6p9lnweMHj19uP+iNiocG679mRm5ybx5T+9wdbKiXuhuoiMDkcNCDNrNrOmALdmIG+Eahz9kgtg/lVQeje0HP+//uOiIrjrEyXER4fzkTtfZcWmymEsUkTk2Bw1IJxzic65pAC3ROfcxFtR7mjOvhF6O+HlX57Qx+Qmx/Lg504jNzmWLz/4BivV3SQiIXIiXUzSX0YxLFgOa+6EQ7tO6KOmZibw4OdOY1pmAtfdt44NFQ3DU6OIyDFQQAynpd+F8EhYccsJf1RyXCR/+txpZCZGc+2dr7Fqe80wFCgiMnQKiOGUlAvn3ATbV8COf57wx6XFR/Hn60+nIC2OT9+7lj++sufEaxQRGSIFxHBb8gVImwZP3XLMczQFkpcSyyPXn865MzL5zuOb+cFfN9OrVelEZAQENSDMbJmZbTOznWZ28yD7nGtm681ss5mt6rf9X/zbNpnZg2YWE8xah01EFFz071C7HdbeNSwfGR8dwR0fL+EzZ03hnpf38Ml71lDdrPWtRSS4ghYQZhYO3ApcDMwBrjGzOQP2SQFuAy53zs0FrvJvzwe+ApQ45+YB4cDyYNU67GYsg2nnw8ofQ2vdsHxkeJjxnUvn8OMPzmftnkO8/zcva1xCRIIqmC2IU4Gd/unBu4CHgCsG7PMR4DHn3D4A51z/czojgFgziwDigLGzTqcZXPRj6GyBlf8xrB99zamT+PPnzyAuOoJP3bOGe1/ePayfLyLSJ5gBkQ+U93te4d/W3wwg1cxWmtk6M/s4gHNuP/DfwD6gEmh0zj0d6EvM7Lq+le5qakbRv6izZsEpn/Eunju4eVg/en5BMk/ccCZLZ2fz/b9u4ZuPbKCtq2dYv0NEJJgBEWiupoGjqxHAYuB9wEXAd8xshpml4rU2puBdsR1vZh8N9CXOuTuccyXOuZLMzMzhq344nHsLxCTDipuHvHb1UMVFRXD7RxfzpfOm8fC6ci799Uts2q91rkVk+AQzICqAwn7PC3hnN1EFsMI51+qcqwVeABYCFwC7nXM1zrlu4DHgjCDWGhxxaXDuv8HuF+Ctvw/7x4eHGTdeNIsHPrOE1s4ePnjbau56cRc+neUkIsMgmAGxFphuZlPMLApvkPmJAfs8DrzHzCLMLA5YAmzF61o6zczizMyApf7tY0/JpyFzNjz9bejpDMpXnFGcwT++ejZnz8jkR3/fypW3r2ZbVXNQvktEJo6gBYRzrge4AXgK78f9YefcZjO73syu9++zFVgBbADWAHc55zY5514DHgFeBzb667wjWLUGVXgELPsPqN8Nr/42aF+TFh/FnR9fzM+uWsju2lbe96sX+fE/ttLcceLXYojIxGTjaS3kkpISV1paGuoyAnvwGq+r6cuvQ2J2UL/qUGsX//HkVh5ZV0FGQjQ3XTSTKxcXEBamJTxE5Ehmts45VxLoNV1JPVLe+yOvi+nZHwT9q9Lio/jvqxbyf186k0lpsdz06AYuv/Ul1uw+FPTvFpHxQwExUtKnwRk3wPoHoOy5EfnKRYUpPPqFM/jl8kXUtXRx9e9e4ZP3rGF3beuIfL+IjG3qYhpJ3e1w+1nQ0wVffMVbrnSEtHX1cM/Le7h9VRldPT4+smQS33jvTBKitayHyESmLqbRIjIWLv8NNJbDM98d0a+Oi4rgS+cV88+vn8NlC/O4d/UezvzP53hozT66e30jWouIjA0KiJFWdDqc9kUo/T1sf2rEvz47KcYbn/jimUzNjOfmxzZyxW9e5sUdNYyn1qSInDgFRCgs/S5kz4PHv3RCa1ifiIWFKTz2hTP47bUnU9PSycd+v4ZP3LNW10+IyGEKiFCIjIEP3QWdzV5IhOhf7mbGxfNzefGm8/jWJbPZWNHAsl++wHX3lbKzuiUkNYnI6KGACJWs2XDhD2HH08O2bsTxiokM53NnT+WfXz+HG84rZnVZHe/9n1V84+E32VunM55EJiqdxRRKzsEDV8GeF+G6Vd4MsKNAbUsnv1tVxn2v7KXH57jy5AK+vLSYgtS4UJcmIsPsaGcxKSBCrfkg/PYMSMyFzz0LEdGhruiw6qYObltZxp/W7MM5x4Vzsrnm1EmcVZyBN0WWiIx1Os11NEvMhituhYMb4fl/D3U1R8hKiuH7l89l1Y3n8pFTJ7Fmdz0f+/0aPnDbap7eXKVZY0XGObUgRosnvgxv3A+ffhoKTwl1NQF19vTy6Lr93LZyJxX17UzNjOeWi2dzwewstShExih1MY0FHU1w2+kQFQeff9E702mU6u71sWJTFb/453bKalo5szidb79vDrNzk0JdmogcI3UxjQUxSXD5r6B2Ozz/o1BXc1SR4WFctjCPFV87mx9cPpfNB5p4369e5Ad/3UxDW1eoyxORYaKAGE2Kl8LiT8HqX4fkKutjFRkexifOmMzKfz2Xa5cUcc/Le7jg56t4cccoWhtcRI6bAmK0Wfaf3lXWf/2adyHdGJASF8UP3z+Pv95wFgnREXzs92v4zv9tUmtCZIxTQIw2kTFw6S+guRKe+lbIrrI+HvMLknnqX87ms2dN4Y+v7uU9P3meh0vLNceTyBilgBiNCk+BM74Mr/8BXvxZqKs5JtER4Xz70jn8/StnMTsviZse2cCn711LVWNHqEsTkWOkgBitLvx/MO9D3rURu18MdTXHbG5eMg997jS+e+kcXtlVx4X/s4oHXtur1oTIGKKAGK3M4LJfQnoxPHQt1O4IdUXHLCzM+PRZU1jx1bOZm5fEt/6yiS8/+AZ1LZ2hLk1EhkABMZpFJ8JHH4PwCHhwOTRWhLqi4zI5I54HP3caN140kxWbqlj681U8tGafrsQWGeUUEKNdSiEs/5O3bsTdy6DpQKgrOi5mxpfOK+YfX30PM7ITufmxjVx5+2q2VjaFujQRGYQCYiyYdBp84glor4cHroa2Q6Gu6LhNz07kf687jZ9dtZA9dW1c+uuX+NHfttDS2RPq0kRkAAXEWJF3Elz9B6jdBneeBwc3h7qi42ZmfGhxAc994xyuLinkrpd2c+5Pn+d/ntmuoBAZRRQQY0nxBfDJJ6G7A+66ALb+LdQVnZCUuCh+/MH5PPbFM1hYkMIvn93B0p+t5IHX9tLZ0xvq8kQmPE3WNxY1V8GD18CBN+CC78OZX/XOehrjXt9Xzw//toU39jWQmxzD9edM48OnFBITGR7q0kTGrZBN1mdmy8xsm5ntNLObB9nnXDNbb2abzWxVv+0pZvaImb1lZlvN7PRg1jqmJObAp56EuR+Af34P/voV6B37XTMnT0rlsS+cwR8/cyr5KbF874nNnP1fz3PLYxu0RrZICAStBWFm4cB24EKgAlgLXOOc29JvnxRgNbDMObfPzLKcc9X+1/4AvOicu8vMooA451zD0b5zwrQg+jgHz/3Qu9p61qXwobsgMjbUVQ0L5xyv7Krj9lW7WLO7js4eH8tPKeTjp09mVk6i1p8QGSYhWQ/C/y/+7zvnLvI/vwXAOffjfvt8Echzzn17wHuTgDeBqe4YCpxwAdHntd/BP74JhUvgqnsgKS/UFQ2rmuZOblu5k/te2Uuvz1FSlMqHTynksoV56n4SOUGh6mLKB8r7Pa/wb+tvBpBqZivNbJ2Zfdy/fSpQA9xjZm+Y2V1mFh/oS8zsOjMrNbPSmpoJOs30ks/DlXdD1Qb47Zmw45+hrmhYZSZG873L5rL65vP5/mVzqGzs4MZHNnDOT5/np0+9RWNbd6hLFBmXghkQgfoABrYGIoDFwPuAi4DvmNkM//aTgd86504CWoGAYxjOuTuccyXOuZLMzMxhK37MmfdBuG4VJOXDn66GNx8KdUXDLjsphk+eOYWXvnkef/rsEmbnJnHbyjLO+q/n+O7jm9hQ0RDqEkXGlYggfnYFUNjveQEw8DLgCqDWOdcKtJrZC8BC4EWgwjn3mn+/RxgkIKSfzBnw6RXw0EfgL5+Hyjfhgh9ARFSoKxtWZsYZxRmcUZzBlgNN3PFCGfe/upf7XtnLeTMz+dJ5xZRMTgt1mSJjXjBbEGuB6WY2xT/IvBx4YsA+jwPvMbMIM4sDlgBbnXNVQLmZzfTvtxTYgry76AS49hFYcj28ehvcczE07At1VUEzJy+JXyw/iVdvWcoN5xWz6UATV97+CsvveIUVm6ro1XxPIsctqNdBmNklwC+AcOBu59y/m9n1AM652/373Ah8CvABdznnfuHfvgi4C4gCdgGfcs7VH+37Juwg9WC2PA6P3wAWBh+4HWZeHOqKgq69q5f7X93Lvav3sL+hnYLUWD571hSuKikkPjqYDWaRsSkkZzGFggIigEO74OFPeAPYZ3wZln4PwiNDXVXQ9fT6+OfWg9z54m7W7a0nKSaCjywp4iOnTqIwLVanyYr4KSAmuu4OeOrfoPT3kF/irXtdeEqoqxox6/bW8/uXdrFiUxU+B3PzkvjJhxYwLz851KWJhJwCQjybHoV/3AytNXDaF+D870BUXKirGjHlh9p4fP1+7nppNw1t3czPT+bKxQVcuiCX9IToUJcnEhIKCHlbZwv88/uw9k5ImwpX3ApFZ4S6qhHV2N7NY69X8HBpxeH1KE6bmsZnz5rKebOyCA9T95NMHAoIeafdL8LjX/LOcJr7ATjnJsiaHeqqRtzWyiae2lzFw2vLOdDYQUZCFBfOyeGC2VmcWZyhK7Vl3FNASGBdrd48Tq/9zns85wovKLLnhrqyEdfd6+OZLQf5+8ZKVr5VTWtXLxkJUZw2NZ1zZ2ZxwewsUuLG1/UkIqCAkHfTdgheudUfFM0w+3I455uQMy/UlYVER3cvr+6q475X9lK65xBNHT2kxUdx0dxsLluYxymT04gM11IqMj4oIGRo2g7Bq7+F126HziZInewFxYLlEDYxfxA7untZXVbLn14rZ3VZLW1dvSTFRHCOv1VxzoxMtSxkTFNAyLFpr4c37vfOejrwBuTMh7O+DjOWTaizngZq6+rhhe01PLu1mue3VVPb0kV4mLG4KJWls7JYOjub4qyEUJcpckwUEHJ8fD7Y+GdY9Z/eBXdx6TD7Mpj5Pig8FWJTQl1hyPh8jjcrGnh2azXPvlV9+GyohYUpLCpI5rKFeSwuStUFeTLqKSDkxPh6YddKWHcvlD3vjVNExMC8K2HxJ6GgZFwseXoi9je089c3D/DMloNsOdBEe3cveckxXDI/l0sW5LIgP5kIjVvIKKSAkOHT3QH7VsOWJ2DDw9DdCpmz4fQveqvaxWkW1dbOHv6+sZKnNx/kubcO4nOQGBPBhXOyOW9mFqdMTiMnOSbUZYoACggJlo4m2PwXWHMnHNzobZt6rjdWUXwhZBSHtLzR4FBrF6vLalm1rYYnN1bS2tULwKycRM6ZkclF83KYlplAcuz4nx9LRicFhASXc7D3ZSh7zptBtm6ntz1ngXdtRXoxTH/vhB7gBu9ai62VTazZfYgVm6p4s6KB7l7v/7/3TM/g/FlZvHduDnnJMRq7kBGjgJCRdWg3bF/hrWpXuf7t7VPOgYXLvYHu6MSQlTdaNLR1sbqsjvXlDTy9uYo9dW0AFKXHcf6sLJZMSees6RkkaJpyCSIFhIROez1UbvACY+OfvYkCLdyb/2n2ZbDoWm+RI2FbVTOvlNWyansNL5fV0dXjIz4qnJOLUllclEpJURonF6UQF6XAkOGjgJDRweeD/aVeN9Rbf4P6PRAWCZNOgwVXw9wPKiz82rp6WF/ewJMbKyndU8+2g804B+FhRniY8Z7iDM6fncX8/GRmZCdqzig5bgoIGZ32vQbb/g7b/gG12yEqAeZ9EKYt9a6zSMoLdYWjRlNHN6/vrad0Tz11rV38Y1MlDW3dAIQZFKXHc+7MTGblJDIvP5k5uUkax5AhUUDI6OYclK+B1++DzY9Bt9cXT9ZcOP1L3kC3WhZHcM5RUd/Oxv2NvFXVzIaKBl7aUUuPfw3uqIgwJqXFMT0rgelZCZw7K4uTJ6WGuGoZjRQQMnb0dELVJih/zQuMmq2QkA0nfRTmXzUhpyQfqp5eH5WNHby8s5aymhb21LVRVt3CnrpWfA5iIsOYnZvE0llZzMlLYlFhKmnxmkdqolNAyNjk88Hel+Cl//Gu5HY+yJ7nXb298Bq1KoaouaObh0srONDQzto9h9hQ0Xj4tczEaE6elMJi/0D43LxkjWdMMAoIGftaqmHz/8H6B7xTZ6MSvIvycuZ7YZFaFOICx45DrV2U1bTw2q46dtW08vq++sOn2EaFhzEnL4mpGfEUpcczOzeRU6ekacbacUwBIeOHc1BRCuvvh12rvDOhAIqXetOSTzsf4tNDWuJYVNvSyet761m3r571+xqoqG+nsrEdn/NC46RJKczPT2ZefjLz8pOYkpGgpVnHCQWEjF+NFfD6H73xiuYDEBkPC66CSadDfom37vYEXcviRDW2dbPtYDPPbKli7Z56tlY20dnjAyAuKpxFhSmcNjWdkyalUJQWT25KjBZSGoMUEDL+9fZ4a1esucM7bbar2dsenQS5CyHvJO82+SyIivduckx6en2U1bSycX8jGysavNCoaqLvJyQ8zChKi2PJ1HTm5iVx8qRUZuYkqqUxyikgZGLx9UL1VjjwuhcaB97wzozyedcNHL44b/ZlkDXHexyuyfKOR2NbN1sqmyivb6P8UBtbDnhzTTV39gCQEB3BgoJkb52MwhQWFqRoJttRRgEh0tPpjV3sfsGbonzbCqjb4b0WnQy5C7yBb18PpE2BtGleKyN3IWTPhTCd2TNUfafbrtl9iPXlDawvb2BrZdPhazSSYyOZlhnP2TMymZmdSHFWApPS44iO0N84FBQQIgP5fN41Fod2wfanoHaHFxyYN9lgXxcVeMFRUOKNacQkQf//Z1ImeSvtRcVDUr53zYbGPN6ho7uXzQca2VDRyM7qFjbubzzidFuA/JRYClJjWTI1nYKUWArT4piWGU9CTITmnwqikAWEmS0DfgmEA3c55/4zwD7nAr8AIoFa59w5/V4LB0qB/c65S9/t+xQQMiycg9Za6Gj0uqnKX/NuBzd712IcTVy6NxFhejF0t0N8pjf2kZjjLayk8DisrauHsupWdtY0s7eujR3VLeypbWXzgaYj9osIM/JSYimZnEpBahxTMuIoKUqjIDVW04kMg5AEhP/HfTtwIVABrAWucc5t6bdPCrAaWOac22dmWc656n6vfx0oAZIUEBJyPZ1eFxQA5oVF3Q7oaoXOFmgsh32vetdpHNoNkXFHtkQSc2Hmxd71GxGx4Hq9EOrphIQsiEmBmGTvlpgzYbu1Orp7qWnuZOP+RiobOyg/1Mau2lZ2HmymqqkDf08VCdERTMtKYFpGPFERYSwuSmVGdiLTshI0RfoxCFVAnA583zl3kf/5LQDOuR/32+eLQJ5z7tsB3l8A/AH4d+DrCggZU3w+r7XQXg9VG6GhHLb/A3Y+5+/KeheRcZBc4A24x6ZCxnSvVZKQDUm53hiJ80F8hhcoE0RXj4/dta28ttu7yG9rZRNlNS109vho7ug5vF9ucgzFWQlMy0wgLiqcWblJLCpIITkuUqv3DXC0gAhmzOYD5f2eVwBLBuwzA4g0s5VAIvBL59x9/td+Adzk3z4oM7sOuA5g0qRJJ1y0yLDo60qKTYUpZ3uPT7rWW9O7eov3w4/zWg2RMW93aXU0eKFSsw2aKyEswruKfNdKePPBwN8VlehdUZ53khcqyQVeC6S50rtOJDbNa6FEJ3ljKH33vl6vGywi2htnCR/9/+qOighjZk4iM3OO/Fnw+Ry761rZWd3CzuoWyqpb2FnTwp9Ly+no8dHre/sfwpPT48hJjmFmdiJp8dFMz04gLyWWyHCjICWOpNgIdV35BfO/iEB/4YHNlQhgMbAUiAVeMbNX8YKj2jm3zj9GMSjn3B3AHeC1IE6wZpHgioyB/JPfuT1lCP+46WyGtkPeKbzth8DCvPBo2u8t+brunrdnwj1WYRGQOsVrpaRP8+6jErxaU6cMbezEOQjRD2tYmDEt02sxXDT3yNe6e31sq2pmfXkD1c2dlFW3sPdQK/+3/gBNHd0M7ERJj4+iIDWW+OgIClPjWDI1jdzkWLKToslKiplQ3VfBPNIKoLDf8wLgQIB9ap1zrUCrmb0ALAROBi43s0uAGCDJzO53zn00iPWKjG7Rid5tsHmnnPNaH40V0FwFcf6WQ1eb1zLpaILOJq+l0tnk7R8Z67Uk2uq88ZS6Mm9t8d7Otz83PBoiYiB7jtcySciBtlrvPT1d3iqBrTXe56ZN8Y+h5EJv19vjNs55Z3qlTPK6xnzd3jhM5kzvave0KV5rq+2Q91194y/t9d6xhEdCeBS0N8ChMq/lFZfudbclF0JsyqB/tsjwMP8UIe/simvv6qWspoWa5k7aunrZe8hrhdS1dNHS2cM/NlXyv6XlR7wnLiqc7KQYClJjmZObRGJMBAnRESTFRlJSlEZyXCRJMRGH83Ist0aCOQYRgTdIvRTYjzdI/RHn3OZ++8wGfgNcBEQBa4DlzrlN/fY5F/hXjUGIjBCfz2uVtNbAwU1ed1dXi3cqcHMlNB/0xj7i0r0f8/h0iM+CqDho2Of9qLfWej/oEdHehYnghVTTAa+1Eh7ptYg6m45aypBFJ3k1JeZ5IeZ8XkAl5XvXuKRO8Z9VluHVZv73RMR4Lab+V9b3awn19PrYU9dKdVMnB5s7vPumTqqbO9hZ3cLu2lY6e3xk0EiRVdFCLJUuja7IRMKA7JheinIyyE+NJy28lbCqDZx2xrkU5BeSmxBORHj4kV17PZ1vL8vrfN7fqKnCC/H2Bmip8v6+znmvt9d7f9PkfLj818f1pwvJGIRzrsfMbgCewjvN9W7n3GYzu97/+u3Oua1mtgLYAPjwToXdNPinikjQhYVBSqF3C9QdNlyc837c6nd7Z3211nirCHa3+08ndt4PeOoUrxXS2+110WXMeLu7ranCazE1lENrtRdQ+9d5P6hRcd6Ejmt+9+61JOZ5La7wKC8UwyIgJpmImGSKY5Ip7vAHWXQCZMyEOAcJ28FqcG11WGfzER/XFRaLDyOmuw3KoX5fIvG0EWW98Ci0umh66SXMemm2RFojU4mjg6SuasLe0RM/QFik170IXsspIRt6Oo75zz8UulBORMYv56DmLa+bKjLWC6T4DK/brLPJC5q6nV5ANR/wgilngffevpMGOhq9EwHCwrx/xddu936g06Z5rZW4NK+bLL3Y/y/+A14LrKfD6/7qbKanpYaO8Hh8hadzaM9GOhqrae7o4VB3JOHttUR31tHQHcFel8OB3mTMHxLNLo6GyCxSk+KJiE3Gl5jDtPwcCtPiyEiIJiMhmqL0uBNaw0NXUouIjAF9S8lurWyirrWLupZOapo7Ka9v52CTd01IU7/TefssmZLG/Z9dclyz6YbqNFcRETkGZkZhWhyFaXGD7tPe1cv+hjb2N3RQ09zJ7lpvUD0YU60rIERExpDYqHCKsxIpzjrqJWLDQhPDiIhIQAoIEREJSAEhIiIBKSBERCQgBYSIiASkgBARkYAUECIiEpACQkREAhpXU22YWQ2w9zjfngHUDmM5Y4GOeWLQMU8Mx3vMRc65zEAvjKuAOBFmVjrYfCTjlY55YtAxTwzBOGZ1MYmISEAKCBERCUgB8bY7Ql1ACOiYJwYd88Qw7MesMQgREQlILQgREQlIASEiIgFN+IAws2Vmts3MdprZzaGuZ7iY2d1mVm1mm/ptSzOzZ8xsh/8+td9rt/j/BtvM7KLQVH1izKzQzJ43s61mttnMvurfPm6P28xizGyNmb3pP+Yf+LeP22PuY2bhZvaGmf3N/3xcH7OZ7TGzjWa23sxK/duCe8zOuQl7A8KBMmAqEAW8CcwJdV3DdGxnAycDm/pt+y/gZv/jm4Gf+B/P8R97NDDF/zcJD/UxHMcx5wIn+x8nAtv9xzZujxswIMH/OBJ4DThtPB9zv2P/OvAn4G/+5+P6mIE9QMaAbUE95onegjgV2Omc2+Wc6wIeAq4IcU3Dwjn3AnBowOYrgD/4H/8BeH+/7Q855zqdc7uBnXh/mzHFOVfpnHvd/7gZ2ArkM46P23la/E8j/TfHOD5mADMrAN4H3NVv87g+5kEE9ZgnekDkA+X9nlf4t41X2c65SvB+TIEs//Zx93cws8nASXj/oh7Xx+3valkPVAPPOOfG/TEDvwBuAnz9to33Y3bA02a2zsyu828L6jFHnECx44EF2DYRz/sdV38HM0sAHgW+5pxrMgt0eN6uAbaNueN2zvUCi8wsBfiLmc07yu5j/pjN7FKg2jm3zszOHcpbAmwbU8fsd6Zz7oCZZQHPmNlbR9l3WI55orcgKoDCfs8LgAMhqmUkHDSzXAD/fbV/+7j5O5hZJF44POCce8y/edwfN4BzrgFYCSxjfB/zmcDlZrYHr1v4fDO7n/F9zDjnDvjvq4G/4HUZBfWYJ3pArAWmm9kUM4sClgNPhLimYHoC+IT/8SeAx/ttX25m0WY2BZgOrAlBfSfEvKbC74Gtzrmf93tp3B63mWX6Ww6YWSxwAfAW4/iYnXO3OOcKnHOT8f6ffc4591HG8TGbWbyZJfY9Bt4LbCLYxxzqkflQ34BL8M52KQO+Fep6hvG4HgQqgW68f018BkgHngV2+O/T+u3/Lf/fYBtwcajrP85jPguvGb0BWO+/XTKejxtYALzhP+ZNwHf928ftMQ84/nN5+yymcXvMeGdavum/be77rQr2MWuqDRERCWiidzGJiMggFBAiIhKQAkJERAJSQIiISEAKCBERCUgBIXIMzKzXP5tm323YZgA2s8n9Z98VCbWJPtWGyLFqd84tCnURIiNBLQiRYeCfq/8n/rUZ1phZsX97kZk9a2Yb/PeT/Nuzzewv/nUc3jSzM/wfFW5md/rXdnjaf3W0SEgoIESOTeyALqYP93utyTl3KvAbvNlG8T++zzm3AHgA+JV/+6+AVc65hXjrdmz2b58O3Oqcmws0AB8K6tGIHIWupBY5BmbW4pxLCLB9D3C+c26Xf8LAKudcupnVArnOuW7/9krnXIaZ1QAFzrnOfp8xGW+67un+598EIp1zPxqBQxN5B7UgRIaPG+TxYPsE0tnvcS8aJ5QQUkCIDJ8P97t/xf94Nd6MowDXAi/5Hz8LfAEOL/iTNFJFigyV/nUicmxi/au39VnhnOs71TXazF7D+4fXNf5tXwHuNrMbgRrgU/7tXwXuMLPP4LUUvoA3+67IqKExCJFh4B+DKHHO1Ya6FpHhoi4mEREJSC0IEREJSC0IEREJSAEhIiIBKSBERCQgBYSIiASkgBARkYD+P273R4WetFZdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd23111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 38\n",
      "Trainable params: 38\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Import Potential Model\n",
    "#155, 162\n",
    "PotModel=load_model('Models/[BEST MODEL] binary4_model00000043.h5')\n",
    "PotModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "43946f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "testing accuracy\n",
      "7/7 [==============================] - 0s 334us/step - loss: 0.6912 - accuracy: 0.6103\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predict = PotModel.predict(x_train)\n",
    "\n",
    "# round predictions\n",
    "round_value = [round(x[0]) for x in predict]\n",
    "print(round_value)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"testing accuracy\")\n",
    "scores = PotModel.evaluate(x_train, y_train)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "48b85f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "testing accuracy\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.5926\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predict = PotModel.predict(x_test)\n",
    "\n",
    "# round predictions\n",
    "round_value = [round(x[0]) for x in predict]\n",
    "print(round_value)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"testing accuracy\")\n",
    "scores = PotModel.evaluate(x_test, y_test)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ec4171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Validation Data\n",
    "df = pd.read_excel('2021Data.xlsx')\n",
    "classification_df=pd.get_dummies(df, columns=['Movement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e1e1906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Net</th>\n",
       "      <th>SC-RPD</th>\n",
       "      <th>DJIA</th>\n",
       "      <th>N225</th>\n",
       "      <th>HSI</th>\n",
       "      <th>SSE</th>\n",
       "      <th>ER</th>\n",
       "      <th>JKSE</th>\n",
       "      <th>dJKSE</th>\n",
       "      <th>Movement_0</th>\n",
       "      <th>Movement_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-30</td>\n",
       "      <td>1431</td>\n",
       "      <td>618</td>\n",
       "      <td>3107</td>\n",
       "      <td>0.323741</td>\n",
       "      <td>30097.2650</td>\n",
       "      <td>27877.220390</td>\n",
       "      <td>28588.284687</td>\n",
       "      <td>3494.176968</td>\n",
       "      <td>14015.0</td>\n",
       "      <td>5964.947461</td>\n",
       "      <td>51.298731</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>10575</td>\n",
       "      <td>3501</td>\n",
       "      <td>23828</td>\n",
       "      <td>0.161690</td>\n",
       "      <td>30154.5875</td>\n",
       "      <td>27984.135586</td>\n",
       "      <td>28740.572031</td>\n",
       "      <td>3499.730452</td>\n",
       "      <td>14012.5</td>\n",
       "      <td>6016.246192</td>\n",
       "      <td>51.298730</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>17389</td>\n",
       "      <td>10486</td>\n",
       "      <td>14886</td>\n",
       "      <td>0.027349</td>\n",
       "      <td>30211.9100</td>\n",
       "      <td>28091.050781</td>\n",
       "      <td>28892.859375</td>\n",
       "      <td>3505.283936</td>\n",
       "      <td>14010.0</td>\n",
       "      <td>6067.544922</td>\n",
       "      <td>-23.704102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>15942</td>\n",
       "      <td>7291</td>\n",
       "      <td>12594</td>\n",
       "      <td>0.043239</td>\n",
       "      <td>30687.4800</td>\n",
       "      <td>28362.169922</td>\n",
       "      <td>29248.699219</td>\n",
       "      <td>3533.685059</td>\n",
       "      <td>14020.0</td>\n",
       "      <td>6043.840820</td>\n",
       "      <td>33.904297</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>13037</td>\n",
       "      <td>5041</td>\n",
       "      <td>10960</td>\n",
       "      <td>0.142753</td>\n",
       "      <td>30723.6000</td>\n",
       "      <td>28646.500000</td>\n",
       "      <td>29307.460938</td>\n",
       "      <td>3517.308105</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>6077.745117</td>\n",
       "      <td>29.470703</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Neg    Pos    Net    SC-RPD        DJIA          N225  \\\n",
       "0 2021-01-30   1431    618   3107  0.323741  30097.2650  27877.220390   \n",
       "1 2021-01-31  10575   3501  23828  0.161690  30154.5875  27984.135586   \n",
       "2 2021-02-01  17389  10486  14886  0.027349  30211.9100  28091.050781   \n",
       "3 2021-02-02  15942   7291  12594  0.043239  30687.4800  28362.169922   \n",
       "4 2021-02-03  13037   5041  10960  0.142753  30723.6000  28646.500000   \n",
       "\n",
       "            HSI          SSE       ER         JKSE      dJKSE  Movement_0  \\\n",
       "0  28588.284687  3494.176968  14015.0  5964.947461  51.298731           0   \n",
       "1  28740.572031  3499.730452  14012.5  6016.246192  51.298730           0   \n",
       "2  28892.859375  3505.283936  14010.0  6067.544922 -23.704102           1   \n",
       "3  29248.699219  3533.685059  14020.0  6043.840820  33.904297           0   \n",
       "4  29307.460938  3517.308105  14000.0  6077.745117  29.470703           0   \n",
       "\n",
       "   Movement_1  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "266bbe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Input and Output for the Model\n",
    "x_valid=classification_df.drop(columns=['Date', 'Pos', 'Neg', 'Net', 'JKSE', 'dJKSE', 'Movement_0', 'Movement_1'])\n",
    "y_valid=classification_df[['Movement_0', 'Movement_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "83f68992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Standardization\n",
    "x_valid=pd.DataFrame(scaler.fit_transform(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "af1c5cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "validation accuracy\n",
      "4/4 [==============================] - 0s 333us/step - loss: 0.6703 - accuracy: 0.6311\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predict = PotModel.predict(x_valid)\n",
    "\n",
    "# round predictions\n",
    "round_value = [round(x[0]) for x in predict]\n",
    "print(round_value)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"validation accuracy\")\n",
    "scores = PotModel.evaluate(x_valid, y_valid)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "587389ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual Movement')\n",
    "    plt.xlabel('Predicted Movement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dbb4f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(predict, axis=1)\n",
    "y_valid_np = y_valid.to_numpy()\n",
    "y_valid = np.argmax(y_valid_np, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4207ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[30 34]\n",
      " [11 47]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels=['Down','Up']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, normalize=False, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ea4617f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6762589928057554"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "f1_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "91a1ff35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103448275862069"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "032950d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5802469135802469"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0c8c705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6311475409836066"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20cd882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.37173072,  0.5958629 ,  0.40016285, -0.56412905],\n",
       "        [-0.17799042, -0.6426176 ,  0.38204446,  0.05554897],\n",
       "        [-0.48850608, -0.5616299 ,  0.14705463, -0.31808946],\n",
       "        [-0.04601592, -0.4070225 , -0.39421993,  0.64648557],\n",
       "        [-0.3688887 , -0.26327568, -0.29829755,  0.4138717 ],\n",
       "        [-0.3892229 , -0.7839111 , -0.37411875, -0.33617115]],\n",
       "       dtype=float32),\n",
       " array([ 0.13013817, -0.11083521, -0.16622609,  0.04994543], dtype=float32),\n",
       " array([[ 0.057498  , -0.67823523],\n",
       "        [-0.32110402,  0.6231728 ],\n",
       "        [ 0.6928722 ,  0.79478663],\n",
       "        [-0.5262585 ,  0.39183244]], dtype=float32),\n",
       " array([-0.04909183, -0.05980563], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PotModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d080b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
