{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceefd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a728f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data and generate Dummy Variables for Movement\n",
    "dta = pd.read_excel('Full Data - Unseparated.xlsx')\n",
    "classification_dta=pd.get_dummies(dta, columns=['Movement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4cd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Input and Output for the Model\n",
    "x=classification_dta.drop(columns=['Date', 'Neg', 'Pos', 'Net', 'SC-RPD', 'SC-Logit', 'JKSE', 'dJKSE', 'Movement_0', 'Movement_1'])\n",
    "y=classification_dta[['Movement_0', 'Movement_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7fb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Train and Test Batches\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Data Standardization\n",
    "scaler=StandardScaler()\n",
    "x_train=pd.DataFrame(scaler.fit_transform(x_train))\n",
    "x_test=pd.DataFrame(scaler.fit_transform(x_test))\n",
    "\n",
    "#Neural Network Model Initiation\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(4, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam(learning_rate=0.0008),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('macro-binary2_model{epoch:08d}.h5', save_freq=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86da422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7525 - accuracy: 0.5540 - val_loss: 0.7212 - val_accuracy: 0.5370\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7491 - accuracy: 0.5634 - val_loss: 0.7181 - val_accuracy: 0.5370\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7457 - accuracy: 0.5634 - val_loss: 0.7152 - val_accuracy: 0.5370\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7423 - accuracy: 0.5681 - val_loss: 0.7125 - val_accuracy: 0.5556\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7395 - accuracy: 0.5775 - val_loss: 0.7099 - val_accuracy: 0.5926\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.5728 - val_loss: 0.7075 - val_accuracy: 0.5926\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.5728 - val_loss: 0.7053 - val_accuracy: 0.5926\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7318 - accuracy: 0.5634 - val_loss: 0.7031 - val_accuracy: 0.5741\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.5587 - val_loss: 0.7011 - val_accuracy: 0.5741\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7266 - accuracy: 0.5587 - val_loss: 0.6992 - val_accuracy: 0.5741\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.5587 - val_loss: 0.6974 - val_accuracy: 0.5926\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.5681 - val_loss: 0.6958 - val_accuracy: 0.5926\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7208 - accuracy: 0.5634 - val_loss: 0.6941 - val_accuracy: 0.5926\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7187 - accuracy: 0.5634 - val_loss: 0.6926 - val_accuracy: 0.5926\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7171 - accuracy: 0.5540 - val_loss: 0.6910 - val_accuracy: 0.5926\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7153 - accuracy: 0.5540 - val_loss: 0.6894 - val_accuracy: 0.5926\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7137 - accuracy: 0.5587 - val_loss: 0.6881 - val_accuracy: 0.5926\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7125 - accuracy: 0.5587 - val_loss: 0.6867 - val_accuracy: 0.5926\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7109 - accuracy: 0.5587 - val_loss: 0.6857 - val_accuracy: 0.5926\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7095 - accuracy: 0.5587 - val_loss: 0.6845 - val_accuracy: 0.5926\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.5587 - val_loss: 0.6834 - val_accuracy: 0.5741\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7069 - accuracy: 0.5587 - val_loss: 0.6823 - val_accuracy: 0.5741\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7058 - accuracy: 0.5587 - val_loss: 0.6813 - val_accuracy: 0.5741\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.5587 - val_loss: 0.6804 - val_accuracy: 0.5741\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7034 - accuracy: 0.5634 - val_loss: 0.6794 - val_accuracy: 0.5741\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.5634 - val_loss: 0.6785 - val_accuracy: 0.5741\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7013 - accuracy: 0.5634 - val_loss: 0.6777 - val_accuracy: 0.5741\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.5634 - val_loss: 0.6770 - val_accuracy: 0.5741\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.5634 - val_loss: 0.6761 - val_accuracy: 0.5741\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6987 - accuracy: 0.5634 - val_loss: 0.6755 - val_accuracy: 0.5741\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.5634 - val_loss: 0.6749 - val_accuracy: 0.5741\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.5634 - val_loss: 0.6741 - val_accuracy: 0.5741\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.5634 - val_loss: 0.6735 - val_accuracy: 0.5741\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6955 - accuracy: 0.5634 - val_loss: 0.6729 - val_accuracy: 0.5741\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5634 - val_loss: 0.6724 - val_accuracy: 0.5741\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5634 - val_loss: 0.6719 - val_accuracy: 0.5741\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5634 - val_loss: 0.6714 - val_accuracy: 0.5741\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5634 - val_loss: 0.6709 - val_accuracy: 0.5741\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5634 - val_loss: 0.6703 - val_accuracy: 0.5741\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.5634 - val_loss: 0.6699 - val_accuracy: 0.5741\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.5634 - val_loss: 0.6695 - val_accuracy: 0.5741\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5634 - val_loss: 0.6691 - val_accuracy: 0.5741\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.5681 - val_loss: 0.6687 - val_accuracy: 0.5741\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.5681 - val_loss: 0.6683 - val_accuracy: 0.5741\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5681 - val_loss: 0.6679 - val_accuracy: 0.5741\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5681 - val_loss: 0.6676 - val_accuracy: 0.5741\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5681 - val_loss: 0.6674 - val_accuracy: 0.5741\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.5681 - val_loss: 0.6673 - val_accuracy: 0.5741\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5681 - val_loss: 0.6670 - val_accuracy: 0.5741\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6872 - accuracy: 0.5681 - val_loss: 0.6667 - val_accuracy: 0.5926\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5728 - val_loss: 0.6664 - val_accuracy: 0.5926\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5728 - val_loss: 0.6662 - val_accuracy: 0.5926\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6861 - accuracy: 0.5728 - val_loss: 0.6659 - val_accuracy: 0.5926\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5728 - val_loss: 0.6656 - val_accuracy: 0.5926\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6854 - accuracy: 0.5728 - val_loss: 0.6652 - val_accuracy: 0.5926\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5728 - val_loss: 0.6651 - val_accuracy: 0.5926\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5728 - val_loss: 0.6648 - val_accuracy: 0.5926\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.5728 - val_loss: 0.6645 - val_accuracy: 0.5926\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5775 - val_loss: 0.6642 - val_accuracy: 0.5926\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.5775 - val_loss: 0.6639 - val_accuracy: 0.5926\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5822 - val_loss: 0.6636 - val_accuracy: 0.5926\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5822 - val_loss: 0.6634 - val_accuracy: 0.5926\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6829 - accuracy: 0.5822 - val_loss: 0.6631 - val_accuracy: 0.5926\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.5822 - val_loss: 0.6629 - val_accuracy: 0.5926\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.5822 - val_loss: 0.6628 - val_accuracy: 0.5926\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.5822 - val_loss: 0.6623 - val_accuracy: 0.6111\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.5775 - val_loss: 0.6620 - val_accuracy: 0.6111\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6815 - accuracy: 0.5775 - val_loss: 0.6619 - val_accuracy: 0.6111\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5822 - val_loss: 0.6618 - val_accuracy: 0.6111\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6809 - accuracy: 0.5869 - val_loss: 0.6616 - val_accuracy: 0.6111\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.5869 - val_loss: 0.6614 - val_accuracy: 0.6111\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.5822 - val_loss: 0.6613 - val_accuracy: 0.6111\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6801 - accuracy: 0.5869 - val_loss: 0.6611 - val_accuracy: 0.6111\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.5822 - val_loss: 0.6609 - val_accuracy: 0.6111\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.5822 - val_loss: 0.6608 - val_accuracy: 0.6111\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.5869 - val_loss: 0.6609 - val_accuracy: 0.6111\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6794 - accuracy: 0.5869 - val_loss: 0.6609 - val_accuracy: 0.6111\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.5915 - val_loss: 0.6607 - val_accuracy: 0.6111\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.5915 - val_loss: 0.6606 - val_accuracy: 0.6111\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5915 - val_loss: 0.6605 - val_accuracy: 0.6111\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5915 - val_loss: 0.6602 - val_accuracy: 0.6111\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5869 - val_loss: 0.6602 - val_accuracy: 0.6111\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.5869 - val_loss: 0.6601 - val_accuracy: 0.6111\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5869 - val_loss: 0.6601 - val_accuracy: 0.6111\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.5869 - val_loss: 0.6599 - val_accuracy: 0.6111\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.5915 - val_loss: 0.6599 - val_accuracy: 0.6111\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.5915 - val_loss: 0.6598 - val_accuracy: 0.5926\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6769 - accuracy: 0.5915 - val_loss: 0.6596 - val_accuracy: 0.5926\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.5822 - val_loss: 0.6595 - val_accuracy: 0.5741\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6765 - accuracy: 0.5822 - val_loss: 0.6593 - val_accuracy: 0.5556\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5822 - val_loss: 0.6592 - val_accuracy: 0.5556\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5869 - val_loss: 0.6592 - val_accuracy: 0.5741\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6757 - accuracy: 0.6103 - val_loss: 0.6591 - val_accuracy: 0.5741\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6150 - val_loss: 0.6591 - val_accuracy: 0.5741\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6753 - accuracy: 0.6150 - val_loss: 0.6590 - val_accuracy: 0.5741\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.6197 - val_loss: 0.6588 - val_accuracy: 0.5741\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.6244 - val_loss: 0.6587 - val_accuracy: 0.5741\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6746 - accuracy: 0.6291 - val_loss: 0.6586 - val_accuracy: 0.5741\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.6244 - val_loss: 0.6586 - val_accuracy: 0.5741\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6742 - accuracy: 0.6244 - val_loss: 0.6587 - val_accuracy: 0.5741\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.6244 - val_loss: 0.6587 - val_accuracy: 0.5926\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.6291 - val_loss: 0.6585 - val_accuracy: 0.5926\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6735 - accuracy: 0.6291 - val_loss: 0.6584 - val_accuracy: 0.6111\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.6291 - val_loss: 0.6583 - val_accuracy: 0.6111\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.6244 - val_loss: 0.6582 - val_accuracy: 0.6111\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6729 - accuracy: 0.6244 - val_loss: 0.6582 - val_accuracy: 0.6111\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6385 - val_loss: 0.6580 - val_accuracy: 0.6111\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.6385 - val_loss: 0.6578 - val_accuracy: 0.6111\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6338 - val_loss: 0.6578 - val_accuracy: 0.6111\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.6291 - val_loss: 0.6577 - val_accuracy: 0.6111\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.6244 - val_loss: 0.6575 - val_accuracy: 0.6111\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6244 - val_loss: 0.6574 - val_accuracy: 0.6111\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6713 - accuracy: 0.6291 - val_loss: 0.6573 - val_accuracy: 0.5926\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.6197 - val_loss: 0.6572 - val_accuracy: 0.5926\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.6197 - val_loss: 0.6570 - val_accuracy: 0.5926\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.6291 - val_loss: 0.6570 - val_accuracy: 0.5926\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.6244 - val_loss: 0.6569 - val_accuracy: 0.5926\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6703 - accuracy: 0.6244 - val_loss: 0.6568 - val_accuracy: 0.5926\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.6244 - val_loss: 0.6568 - val_accuracy: 0.5926\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.6244 - val_loss: 0.6567 - val_accuracy: 0.5926\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6244 - val_loss: 0.6566 - val_accuracy: 0.6111\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.6244 - val_loss: 0.6566 - val_accuracy: 0.6111\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.6291 - val_loss: 0.6564 - val_accuracy: 0.6111\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.6291 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.6385 - val_loss: 0.6564 - val_accuracy: 0.6111\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.6291 - val_loss: 0.6561 - val_accuracy: 0.6111\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.6291 - val_loss: 0.6562 - val_accuracy: 0.6111\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6684 - accuracy: 0.6291 - val_loss: 0.6562 - val_accuracy: 0.6111\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.6291 - val_loss: 0.6560 - val_accuracy: 0.6111\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6680 - accuracy: 0.6244 - val_loss: 0.6560 - val_accuracy: 0.6111\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6678 - accuracy: 0.6197 - val_loss: 0.6559 - val_accuracy: 0.5926\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6291 - val_loss: 0.6559 - val_accuracy: 0.5926\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6675 - accuracy: 0.6291 - val_loss: 0.6560 - val_accuracy: 0.5926\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.6291 - val_loss: 0.6560 - val_accuracy: 0.5926\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6672 - accuracy: 0.6291 - val_loss: 0.6560 - val_accuracy: 0.5926\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6291 - val_loss: 0.6557 - val_accuracy: 0.5926\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.6291 - val_loss: 0.6559 - val_accuracy: 0.5926\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6667 - accuracy: 0.6291 - val_loss: 0.6558 - val_accuracy: 0.5926\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6291 - val_loss: 0.6559 - val_accuracy: 0.5926\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.6244 - val_loss: 0.6557 - val_accuracy: 0.5926\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.6150 - val_loss: 0.6557 - val_accuracy: 0.6111\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.6150 - val_loss: 0.6557 - val_accuracy: 0.5926\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6150 - val_loss: 0.6555 - val_accuracy: 0.5926\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.6197 - val_loss: 0.6554 - val_accuracy: 0.5926\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6657 - accuracy: 0.6197 - val_loss: 0.6553 - val_accuracy: 0.5926\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6197 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.6197 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6653 - accuracy: 0.6197 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.6244 - val_loss: 0.6550 - val_accuracy: 0.5926\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6649 - accuracy: 0.6291 - val_loss: 0.6549 - val_accuracy: 0.6111\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.6291 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.6432 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.6385 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.6432 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.6432 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6640 - accuracy: 0.6432 - val_loss: 0.6546 - val_accuracy: 0.6111\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.6432 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.6432 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.6432 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6633 - accuracy: 0.6432 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6432 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.6432 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6629 - accuracy: 0.6432 - val_loss: 0.6546 - val_accuracy: 0.6111\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6432 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.6432 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6620 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.5926\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6479 - val_loss: 0.6547 - val_accuracy: 0.5926\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.5926\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.6479 - val_loss: 0.6549 - val_accuracy: 0.6111\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.6479 - val_loss: 0.6547 - val_accuracy: 0.6296\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6612 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6432 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6609 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6385 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6432 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6604 - accuracy: 0.6432 - val_loss: 0.6547 - val_accuracy: 0.6296\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6601 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.6526 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6479 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6596 - accuracy: 0.6479 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6479 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6593 - accuracy: 0.6479 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.6526 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6479 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.6479 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6479 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6479 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6479 - val_loss: 0.6547 - val_accuracy: 0.6296\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.6479 - val_loss: 0.6547 - val_accuracy: 0.6296\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6526 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.6432 - val_loss: 0.6549 - val_accuracy: 0.6296\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6385 - val_loss: 0.6548 - val_accuracy: 0.6296\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.6385 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6573 - accuracy: 0.6385 - val_loss: 0.6550 - val_accuracy: 0.6296\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6568 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6338 - val_loss: 0.6552 - val_accuracy: 0.6111\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.6291 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6560 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.6296\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6556 - accuracy: 0.6338 - val_loss: 0.6550 - val_accuracy: 0.6111\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.6338 - val_loss: 0.6552 - val_accuracy: 0.6111\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.6338 - val_loss: 0.6552 - val_accuracy: 0.6111\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6338 - val_loss: 0.6552 - val_accuracy: 0.6111\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.6291 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.6291 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6291 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.6291 - val_loss: 0.6550 - val_accuracy: 0.6111\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6291 - val_loss: 0.6550 - val_accuracy: 0.6111\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.6291 - val_loss: 0.6549 - val_accuracy: 0.6111\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.6291 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.6338 - val_loss: 0.6550 - val_accuracy: 0.6111\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6538 - accuracy: 0.6338 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.6291 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6291 - val_loss: 0.6548 - val_accuracy: 0.6111\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.6244 - val_loss: 0.6547 - val_accuracy: 0.6111\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6291 - val_loss: 0.6548 - val_accuracy: 0.5926\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6531 - accuracy: 0.6244 - val_loss: 0.6548 - val_accuracy: 0.5926\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6291 - val_loss: 0.6548 - val_accuracy: 0.5926\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6244 - val_loss: 0.6549 - val_accuracy: 0.5926\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.6244 - val_loss: 0.6549 - val_accuracy: 0.5926\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6291 - val_loss: 0.6548 - val_accuracy: 0.5926\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.6291 - val_loss: 0.6549 - val_accuracy: 0.5926\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.6338 - val_loss: 0.6549 - val_accuracy: 0.5926\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.6338 - val_loss: 0.6550 - val_accuracy: 0.5926\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6338 - val_loss: 0.6550 - val_accuracy: 0.5926\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.5926\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.5926\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6338 - val_loss: 0.6551 - val_accuracy: 0.5926\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6514 - accuracy: 0.6385 - val_loss: 0.6550 - val_accuracy: 0.5926\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6512 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.5926\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.6338 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.6338 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.5926\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.6385 - val_loss: 0.6550 - val_accuracy: 0.5926\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6504 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.5926\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6385 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6500 - accuracy: 0.6385 - val_loss: 0.6552 - val_accuracy: 0.5926\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.6385 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6432 - val_loss: 0.6550 - val_accuracy: 0.6111\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.6432 - val_loss: 0.6550 - val_accuracy: 0.6111\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6432 - val_loss: 0.6550 - val_accuracy: 0.6111\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.6432 - val_loss: 0.6551 - val_accuracy: 0.6111\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.6432 - val_loss: 0.6552 - val_accuracy: 0.6111\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.6432 - val_loss: 0.6552 - val_accuracy: 0.6111\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.6432 - val_loss: 0.6553 - val_accuracy: 0.6111\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6432 - val_loss: 0.6553 - val_accuracy: 0.6111\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.6432 - val_loss: 0.6552 - val_accuracy: 0.6111\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6482 - accuracy: 0.6432 - val_loss: 0.6555 - val_accuracy: 0.6111\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6432 - val_loss: 0.6556 - val_accuracy: 0.6111\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6432 - val_loss: 0.6555 - val_accuracy: 0.6111\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6432 - val_loss: 0.6556 - val_accuracy: 0.6111\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6432 - val_loss: 0.6555 - val_accuracy: 0.6111\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.6432 - val_loss: 0.6555 - val_accuracy: 0.6111\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.6432 - val_loss: 0.6556 - val_accuracy: 0.6111\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.6432 - val_loss: 0.6557 - val_accuracy: 0.6111\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6432 - val_loss: 0.6557 - val_accuracy: 0.6111\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6432 - val_loss: 0.6559 - val_accuracy: 0.6111\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.6432 - val_loss: 0.6558 - val_accuracy: 0.6111\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.6432 - val_loss: 0.6558 - val_accuracy: 0.6111\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.6432 - val_loss: 0.6558 - val_accuracy: 0.6111\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6432 - val_loss: 0.6558 - val_accuracy: 0.6111\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6432 - val_loss: 0.6558 - val_accuracy: 0.6111\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.6432 - val_loss: 0.6558 - val_accuracy: 0.6111\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6432 - val_loss: 0.6559 - val_accuracy: 0.6111\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6457 - accuracy: 0.6432 - val_loss: 0.6560 - val_accuracy: 0.6111\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6455 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6111\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6432 - val_loss: 0.6562 - val_accuracy: 0.6111\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6452 - accuracy: 0.6432 - val_loss: 0.6562 - val_accuracy: 0.6111\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6111\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6450 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6111\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6111\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6479 - val_loss: 0.6561 - val_accuracy: 0.6111\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6446 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6111\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6111\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6445 - accuracy: 0.6479 - val_loss: 0.6563 - val_accuracy: 0.6111\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6479 - val_loss: 0.6564 - val_accuracy: 0.6111\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6479 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6479 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6432 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6437 - accuracy: 0.6432 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6479 - val_loss: 0.6565 - val_accuracy: 0.6111\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6111\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6111\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6111\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6111\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6111\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6423 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6296\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6296\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6412 - accuracy: 0.6479 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.6479 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6479 - val_loss: 0.6568 - val_accuracy: 0.6296\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.6479 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6479 - val_loss: 0.6569 - val_accuracy: 0.6296\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.6432 - val_loss: 0.6570 - val_accuracy: 0.6296\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6432 - val_loss: 0.6573 - val_accuracy: 0.6111\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6432 - val_loss: 0.6573 - val_accuracy: 0.6111\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6402 - accuracy: 0.6479 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6398 - accuracy: 0.6479 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.6432 - val_loss: 0.6575 - val_accuracy: 0.6296\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6391 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6479 - val_loss: 0.6576 - val_accuracy: 0.6111\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6479 - val_loss: 0.6575 - val_accuracy: 0.6296\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6111\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6111\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6111\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6111\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6111\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6432 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6432 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6375 - accuracy: 0.6432 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6432 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6374 - accuracy: 0.6432 - val_loss: 0.6575 - val_accuracy: 0.6481\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6479 - val_loss: 0.6575 - val_accuracy: 0.6481\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6481\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6370 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.6479 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6367 - accuracy: 0.6432 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6432 - val_loss: 0.6575 - val_accuracy: 0.6296\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6364 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6526 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6296\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6479 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.6479 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6479 - val_loss: 0.6571 - val_accuracy: 0.6296\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6526 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6354 - accuracy: 0.6479 - val_loss: 0.6572 - val_accuracy: 0.6296\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6350 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6432 - val_loss: 0.6574 - val_accuracy: 0.6296\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.6479 - val_loss: 0.6572 - val_accuracy: 0.6481\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6479 - val_loss: 0.6572 - val_accuracy: 0.6481\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6479 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.6432 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6432 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6432 - val_loss: 0.6572 - val_accuracy: 0.6481\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.6479 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6481\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6332 - accuracy: 0.6479 - val_loss: 0.6576 - val_accuracy: 0.6481\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6479 - val_loss: 0.6576 - val_accuracy: 0.6481\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6526 - val_loss: 0.6574 - val_accuracy: 0.6481\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6481\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6526 - val_loss: 0.6575 - val_accuracy: 0.6481\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.6479 - val_loss: 0.6575 - val_accuracy: 0.6481\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6479 - val_loss: 0.6576 - val_accuracy: 0.6481\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6479 - val_loss: 0.6575 - val_accuracy: 0.6481\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6322 - accuracy: 0.6479 - val_loss: 0.6574 - val_accuracy: 0.6481\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6526 - val_loss: 0.6575 - val_accuracy: 0.6481\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.6526 - val_loss: 0.6574 - val_accuracy: 0.6481\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6526 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6526 - val_loss: 0.6575 - val_accuracy: 0.6481\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.6526 - val_loss: 0.6573 - val_accuracy: 0.6481\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6312 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6311 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6481\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.6526 - val_loss: 0.6572 - val_accuracy: 0.6481\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6526 - val_loss: 0.6570 - val_accuracy: 0.6481\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.6526 - val_loss: 0.6568 - val_accuracy: 0.6481\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6526 - val_loss: 0.6568 - val_accuracy: 0.6481\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6526 - val_loss: 0.6567 - val_accuracy: 0.6481\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6303 - accuracy: 0.6526 - val_loss: 0.6566 - val_accuracy: 0.6481\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6526 - val_loss: 0.6565 - val_accuracy: 0.6481\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6479 - val_loss: 0.6566 - val_accuracy: 0.6481\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6481\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6526 - val_loss: 0.6568 - val_accuracy: 0.6481\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.6526 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6620 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.6620 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.6620 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6573 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.6573 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6573 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6620 - val_loss: 0.6568 - val_accuracy: 0.6667\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.6620 - val_loss: 0.6568 - val_accuracy: 0.6667\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6620 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6620 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.6620 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6286 - accuracy: 0.6620 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.6620 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6620 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6282 - accuracy: 0.6620 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6620 - val_loss: 0.6572 - val_accuracy: 0.6667\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6283 - accuracy: 0.6620 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6279 - accuracy: 0.6620 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6620 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.6620 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6620 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6620 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.6620 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6620 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.6620 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6620 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6620 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.6526 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6266 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6479 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6479 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6264 - accuracy: 0.6573 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6526 - val_loss: 0.6569 - val_accuracy: 0.6667\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6264 - accuracy: 0.6526 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.6526 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6526 - val_loss: 0.6568 - val_accuracy: 0.6667\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6259 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6479 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.6479 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6255 - accuracy: 0.6479 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.6479 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.6479 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.6479 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6432 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.6432 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6249 - accuracy: 0.6432 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6432 - val_loss: 0.6559 - val_accuracy: 0.6667\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6247 - accuracy: 0.6432 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6479 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6432 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6244 - accuracy: 0.6432 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.6479 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6241 - accuracy: 0.6479 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.6479 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.6479 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.6479 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.6432 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6432 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6479 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6234 - accuracy: 0.6432 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6231 - accuracy: 0.6385 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.6479 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6479 - val_loss: 0.6559 - val_accuracy: 0.6667\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.6479 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.6479 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6479 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6227 - accuracy: 0.6479 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.6432 - val_loss: 0.6559 - val_accuracy: 0.6667\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.6479 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6479 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6479 - val_loss: 0.6556 - val_accuracy: 0.6667\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.6432 - val_loss: 0.6560 - val_accuracy: 0.6667\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6432 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6217 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.6432 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6432 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.6479 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6214 - accuracy: 0.6432 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6479 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6210 - accuracy: 0.6479 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6479 - val_loss: 0.6563 - val_accuracy: 0.6667\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.6479 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.6526 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.6526 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6209 - accuracy: 0.6526 - val_loss: 0.6563 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, callbacks= checkpoint, batch_size= 32, epochs= 500, validation_data= (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b44a214",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd23111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Import Potential Model\n",
    "#155, 162\n",
    "PotModel=load_model('macro-binary2_model00000156.h5')\n",
    "PotModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43946f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "training accuracy\n",
      "7/7 [==============================] - 0s 500us/step - loss: 0.6639 - accuracy: 0.6432\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predict = PotModel.predict(x_train)\n",
    "\n",
    "# round predictions\n",
    "round_value = [round(x[0]) for x in predict]\n",
    "print(round_value)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"training accuracy\")\n",
    "scores = PotModel.evaluate(x_train, y_train)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48b85f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "testing accuracy\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.6546 - accuracy: 0.6111\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predict = PotModel.predict(x_test)\n",
    "\n",
    "# round predictions\n",
    "round_value = [round(x[0]) for x in predict]\n",
    "print(round_value)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"testing accuracy\")\n",
    "scores = PotModel.evaluate(x_test, y_test)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec4171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Validation Data\n",
    "df = pd.read_excel('2021Data.xlsx')\n",
    "classification_df=pd.get_dummies(df, columns=['Movement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "266bbe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Input and Output for the Model\n",
    "x_valid=classification_df.drop(columns=['Date', 'Pos', 'Neg', 'Net', 'SC-RPD', 'JKSE', 'dJKSE', 'Movement_0', 'Movement_1'])\n",
    "y_valid=classification_df[['Movement_0', 'Movement_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83f68992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Standardization\n",
    "x_valid=pd.DataFrame(scaler.fit_transform(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "af1c5cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "validation accuracy\n",
      "4/4 [==============================] - 0s 334us/step - loss: 0.6907 - accuracy: 0.5492\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predict = PotModel.predict(x_valid)\n",
    "\n",
    "# round predictions\n",
    "round_value = [round(x[0]) for x in predict]\n",
    "print(round_value)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"validation accuracy\")\n",
    "scores = PotModel.evaluate(x_valid, y_valid)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "587389ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual Movement')\n",
    "    plt.xlabel('Predicted Movement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dbb4f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(predict, axis=1)\n",
    "#y_valid_np = y_valid.to_numpy()\n",
    "y_valid = np.argmax(y_valid_np, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4207ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[33 31]\n",
      " [24 34]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels=['Down','Up']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, normalize=False, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea4617f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5528455284552846"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "f1_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "91a1ff35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5862068965517241"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "032950d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230769230769231"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0c8c705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5491803278688525"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20cd882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.21397   ,  0.75286275,  0.01982591, -0.37916964],\n",
       "        [-0.33899993, -0.13339408,  0.8935695 , -0.07461214],\n",
       "        [-0.09507138,  0.5386962 ,  0.22045313, -0.12539059],\n",
       "        [-0.4253423 , -0.14527892, -0.57737905,  0.42981464],\n",
       "        [ 0.01425722, -0.32060605,  0.42372206,  0.26541483]],\n",
       "       dtype=float32),\n",
       " array([-0.2642933 ,  0.22931589,  0.01471828, -0.07020838], dtype=float32),\n",
       " array([[-0.56197125,  0.15290758],\n",
       "        [-0.51084167,  0.54520994],\n",
       "        [ 0.24008128, -0.58489853],\n",
       "        [-0.02252161, -0.44383144]], dtype=float32),\n",
       " array([0.04951724, 0.14308757], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PotModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677952fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
